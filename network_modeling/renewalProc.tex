\chapter{Renewal Processes (Cap 7)}
The main idea of a renewal process is a cyclic recurrence of a random fenomena presenting always the same statistics.
The classical example is the lifetime of a light bulb: everytime a blub dies the new one experience the same conditions as the previous one.

\begin{definition}[Renewal Process]
	More formally, a renewal process is a sequence of i.i.d. r.v. $X_i$ that satisfy these constraints:

	\begin{itemize}
		\item $ \forall i, F_i(x) = P[X_i < x] = F(x) \rightarrow $ lifetimes are statistically equivalent
		\item $ F(0) = 0 \rightarrow $ renewals are not simultanous
		\item $ F(+\infty) = 0 \rightarrow $ renewals repeat forever
	\end{itemize}
\end{definition}

\begin{remark}[Markov chain as renewal processes]
	Given this definition, in a \gls{mc} each arrival at a given state can be considered as a renewal instant.

	In fact, for the Markov property the future evolution depends only on the current state, so behaviour of the process through a given node is the same after every passage.
\end{remark}

\begin{remark}[Poisson process as renewal processes]
	A similar reasoning is straightforward to apply to Poisson processes: each new arrival is statistically equivalent to the first one, since they are all \emph{memoryless} and identically distributed.
\end{remark}

\section{Relevant quantities}

\subsection{Count of renewals}
	Each $X_i$ can be reported as a progress on a plot, marking each renewal event and the time intervals between them.

	\#TODO Graph

	where
	\begin{itemize}
		\item $ S_n = W_n = \sum\limits_{k=1}^n X_k =$ time of the n-th renewal
		\item $ N(t) = $ number of events in $(0, t] = \max\,\{n : W_n \le t \}$
	\end{itemize}

	Since all variables are indipendent from the past, the knowledge of $N(t)$ or $W_n$ allows to fully characterize the process.

\subsection{Renewal function}
	Given a serie of renewals, it can be interesting to obtain the probability distribution on the \emph{n}-th event: since it describes a sum of i.i.d. r.v., it is the \emph{n}-th convolution of $F(x)$ with itself.

	\begin{equation}
		F_n(t) = \prob[W_n \le t] \stackrel{(*)}{=} \prob[N(t) \ge n]
	\end{equation}
	where (*) holds for $W_n$ definition.

		\begin{definition}[Renewal function]
			The sum over $n$ of these probabilities gives the expected number of renewals at time $t$, defined as $M(t)$ and called \emph{renewal function}.

			\begin{equation}
				M(t) = \exp[N(t)] = \sum\limits_{k=1}^{+\infty}\prob[N(t)\ge k] = \sum\limits_{k=1}^{+\infty} F_k(t)
			\end{equation}
		\end{definition}

\subsection{Time intervals}
	Other parameters of interest are the times of the renewals that are close to a time instant $t$, that is used to split the inter-renewal time.

	\begin{equation} \begin{cases}
		\delta_t = t - W_{N(t)} & \rightarrow
			\text{~~current life (or age)} \\
		\gamma_t = W_{N(t)+1}-t & \rightarrow
			\text{~~residual lifetime} \\
		\beta_t = \delta_t + \gamma_t & \rightarrow
			\text{~~total lifetime}
	\end{cases} \end{equation}

	\bigbreak
	An interesting result can be proven for Poisson processes with intensity $\lambda$.
	In this case, given $\beta_t = \delta_t + \gamma_t$, the joint distribution of $\delta_t$ and $\gamma_t$ can be written as follows.

	\begin{equation}
		\prob[\gamma_t > x, \delta_t > y ] =
		\begin{cases}
			e^{-\lambda \cdot (x+y)} & \text{if } y < t \\
			0 & \text{if } y \ge t \\
		\end{cases}
	\end{equation}
	where the second case takes into account that the previous event can not happen before time 0.

	The expectation of $\beta_t$ can be computed naturally as
	\begin{equation*}
		\exp[\beta_t] = \exp[\gamma_t] + \exp[\delta_t] =
		\frac{1}{\lambda} + \exp[\delta_t] =
		\frac{1}{\lambda} + \int_0^t e^{-\lambda \cdot x} dx =
		\frac{2-e^{-\lambda \cdot t}}{\lambda}
	\end{equation*}
	where again it is taken into account that $\delta_t$ must be smaller than $t$, i.e. the last renewal cannot happen before 0.

	The asymptotic behaviour of this parameter, that gets rid of the transient component, gives this surprising result.
	\begin{equation*}
		\lim_{t \to +\infty} \exp[\beta_t] = \lim_{t \to +\infty} \frac{2-e^{-\lambda \cdot t}}{\lambda} = \frac{2}{\lambda} > \frac{1}{\lambda} = \exp[X] \text{ where } X \sim exp(\lambda)
	\end{equation*}
	This result is indeed correct, but it clashes with our previous knowledge of the mean interarrivals time $X$ for Poisson process.
	This paradox is easily explained with the concept of \emph{picking bias}: the choice of a random observation instant $t$ changes the statistical behaviour of the time interval, since bigger ones are privileged.

\section{Asymptotic results}
\begin{theorem}[Ross p. 101 and passim]
	Given a renewal process made of a sequence $X_k$ i.i.d. r.v., we can state that, with probability 1,
	\begin{numcases}{}
		\lim_{t \to +\infty} N(t) = N(\infty) = +\infty \label{eq:nt_to_infty} \\
		\lim_{n \to +\infty} \frac {S_n} {n} =
			\exp[X] <+\infty\quad \label{eq:renewal_partial_sum} \\
		\lim_{t \to +\infty} \frac{N(t)}{t} = \frac{1}{\mu} \label{eq:nt_grows_linearly}
	\end{numcases}
\end{theorem}
% In essence this results states that in finite time we have a finite number of renewals. Viceversa in infinite time we have infinite renewals.

\begin{proof}
	\proofpart (equation \ref{eq:nt_to_infty})

	In have infinite time, we have a finite number of renewals if and ony if there exists an event that is the last one, i.e. its assiciated renewal time $X_k$ takes an infinite amount of time.
	\begin{equation*}
		\begin{split}
			\prob[N(\infty)<\infty] &= \prob[X_n = \infty \text{ for some n}] = \prob \left[ \bigcup\limits_{n=1}^{+\infty}\{X_n = \infty \} \right] \\
			&\le \sum\limits_{n=1}^{+\infty}\prob[X_n = \infty] = 0 \text{~because~} F(\infty)=1
		\end{split}
	\end{equation*}

	\proofpart (equation \ref{eq:renewal_partial_sum})

	By $S_n$ definition, we have that $ S_{N(t)} / N(t)$ is the average interarrival time for the first $N(t)$ renewals and so for the \emph{Strong Law of Large Numbers} we have that this time average converges to the expectation.
	$$ \lim_{t \to +\infty} \frac{S_{N(t)}}{N(t)} = \lim_{t \to +\infty} \frac{S_{N(t)+1}}{N(t)+1} = \lim_{N \to +\infty} \frac{S_{N}}{N} = \mu $$

	\proofpart (equation \ref{eq:nt_grows_linearly})

	By $S_n$ and $N(t)$ definitions, we have that $S_{N(t)}$ and $S_{N(t)+1}$ are respectively the time of the last and the next renewal of a given time $t$.

	\begin{equation*}
			S_{N(t)} \le t < S_{N(t)+1} \implies
			\frac{S_{N(t)}}{N(t)} \le \frac{t}{N(t)} < \frac{S_{N(t)+1}}{N(t)} =\frac{S_{N(t)+1}}{N(t)+1} \cdot \frac{N(t)+1}{N(t)}
	\end{equation*}

	Finally, for the sandwich theorem and for equation \ref{eq:renewal_partial_sum}, we have that
	$$ \mu \le \lim_{t \to +\infty} \frac{t}{N(t)} \stackrel{(*)}{\le}\mu \quad \implies \lim_{t \to +\infty} \frac{t}{N(t)} = \mu $$
	Where in $(*)$ the strict $<$ became $\le$ as we were dealing with limits.
\end{proof}


\begin{theorem}[K.T. page 102]
	We will now prove some interesting properties of the renewal function $M(t)$.

	\begin{numcases}{}
		\lim_{n \to +\infty} F_n(t) = 0 \text{ at least geometrically} \label{eq:Fn_geometric_decreasing} \\
		\forall t, \, M(t) < +\infty \label{eq:mt_always_finite} \\
		\lim_{t \to +\infty} M(t) = +\infty \label{eq:mt_diverges}
	\end{numcases}

\end{theorem}
\begin{proof}
	\proofpart (equation \ref{eq:Fn_geometric_decreasing})
	Considering the distributions of the $r$-th renewal, we can state that

	\begin{equation}
		\exists r > 0: F_r(t) = \prob[S_r \le t] = \prob \left[ \sum_{i=1}^r X_i \le t \right] < 1
	\end{equation}

	Conversely, we can show that

	\begin{equation} \begin{split}
		\forall t, \exists r: ~ \prob[S_r > t] & = \prob \left[ \sum_{i=1}^r X_i > t \right]
			\ge \prob \left[ X_k > \frac{t}{r} \,\forall k=1, \ldots, r \right] = \\
		& = \left( \prob \left[ X_k > \frac{t}{r} \right] \right) ^ r =
			\left( 1 - F \left( \frac{t}{r} \right) \right) ^ r > 0
	\end{split} \end{equation}

	Thus we have proved that $ \lim_{n \to +\infty} F_r(t) = 0 $ at least geometrically.

	\proofpart (equation \ref{eq:mt_always_finite} and \ref{eq:mt_diverges})
	First we derive a nice property of $F_n(t)$ distributions that holds for every $m \in [1,\, n-1]$:

	\begin{equation} \label{eq:fn_upper_bound}
		\begin{split}
			F_n(t) &= \int\limits_0^t F_{n-m}(t-\xi) dF_m(\xi) \quad\\
			& \le \int\limits_0^t F_{n-m}(t) dF_m(\xi) \le F_{n-m} \cdot F_m(t)
		\end{split}
	\end{equation}

	We will use this property to set an upper bound for $M(t)$, as follows

	\begin{equation} \label{eq:mt_convergence}
		\begin{split}
			M(t) &= \exp[N(t)] = \sum\limits_{j=1}^{+\infty} F_j(t) = \sum\limits_{n=0}^{+\infty} \sum\limits_{k=1}^{r} F_{n r + k}(t) \le \\
			& \stackrel{(1)}{\le} \sum\limits_{n=0}^{+\infty} \sum\limits_{k=1}^{r} F_r(t) \, F_{(n-1) r + k}(t) \le \\
			& \stackrel{(1)}{\le} \sum\limits_{n=0}^{+\infty} \sum\limits_{k=1}^{r} F_r(t) \left[ F_r(t) \, F_{(n-2) r + k}(t) \right] = \\
			& = \sum\limits_{n=0}^{+\infty} \sum\limits_{k=1}^{r} F^2_r(t) \, F_{(n-2) r + k}(t) \le \ldots \stackrel{(2)}{\le} \sum\limits_{n=0}^{+\infty} F^n_r(t) \sum\limits_{k=1}^{r} F_k(t)
		\end{split}
	\end{equation}
	where
	\begin{itemize}
		\item[(1)] both hold by applying equation \ref{eq:fn_upper_bound}
		\item[(2)] is obtained applying \ref{eq:fn_upper_bound} recursevely
	\end{itemize}

	While the latter term on $k$ is always finite, since it is a finite sum, the former converges only if the $F_r(t)$ terms converge at least geometrically.

	The two thesis are then proved.

	\begin{equation}
		\begin{dcases}
			M(t) \le \sum\limits_{n=0}^{+\infty} F^n_r(t) \sum\limits_{k=1}^{r} F_k(t) < + \infty & \text{for finite } t \\
			M(t) = +\infty & \text{ for } t \to +\infty
		\end{dcases}
	\end{equation}
	where the latter holds since
	$$ \lim_{t \to +\infty}M(t) = \lim_{t \to +\infty} \sum\limits_{j=1}^{+\infty} F_j(t) = +\infty \text{ since } \lim_{t \to +\infty} F_j(t) = 1 $$
\end{proof}

\section{Renewal argument}

% \begin{definition}[Convolution]
% 	For any monothonic function $A$ and for any well behaved function $B$ we define the convolution as
% 	\begin{equation}\begin{split}
% 		A \ast B &= \int\limits_0^t B(t-\eta)\cdot dA(\eta) = B \ast A \\
% 		% & \implies \int a(t-x)\cdot dM(x) = M \ast a ~(t)
% 	\end{split}\end{equation}
% \end{definition}

% \begin{remark}[Expectation as convolution]
% 	We can observe that, for continue random variables, the expectation is a convolution that deals with probability distributionss.
% 	$$ \exp[a(t-X)]=\int a(t-x)\cdot dF(x) $$
% \end{remark}

The \emph{renewal argument} is less a proved result than a way of solve problems during the analysis of renewal processes.

It consists of conditioning on the first renewal and then build a recursive equation on the quantity of desire. For example, to compute $M(t)$ one could proceed as follows.

\begin{equation}
	\exp[N(t)| X_1 = x] =
	\begin{cases}
	0 & x>t \\
	1+M(t-x) & x \le t
	\end{cases}
\end{equation}
where in the first case the renewal has yet to happen, while in the second it is counted and the quantity $M$ is computed on the remaining time.

Averaging on the first event distribution, we can get the unconditioned value of $M(t)$:
\begin{equation} \label{eq:mt_renewal_equation}
	\begin{split}
	M(t)= \exp[N(t)]&=\int\limits_0^{+\infty}\exp[N(t)|X_1=x] \cdot dF(x)\\
	&=\int\limits_0^{t}[1+M(t-x)] \cdot dF(x)\\
	&= F(t) + \int\limits_0^{t}M(t-x) \cdot dF(x)\\
	&= F(t) + F \ast M ~ (t)
	\end{split}
\end{equation}

\section{Renewal equations}

\begin{definition}[Renewal Equation]
	Formulas like \ref{eq:mt_renewal_equation} are so often encountered in these field of study that they took the name of \emph{renewal equations}.

	\begin{equation} \label{eq:renewal_equation}
			A(t) = a(t) +\int\limits_0^{t}A(t-x) \cdot dF(x)
	\end{equation}
	with $a(t)$ given and $F(x)$ a probability distribution.

	Setting $a(t) = F(t)$ and $A(t) = M(t)$ we obtain the equation \ref{eq:mt_renewal_equation}.
\end{definition}

\begin{theorem}[4.1 K.T. p.184]
	Let a(t) be a bounded function, the renewal equation has an unique solution $A(t)$ bounded on finite intervals, that is
	\begin{equation} \label{eq:renewal_solution}
		A(t) = a(t) + \int\limits_0^{t} a(t-x) ~ dM(x)
	\end{equation}
\end{theorem}
In other words it exists an unique solution that doesn't diverge in a finite time.
\begin{proof}
	The proof is in three steps: boundness, existence and uniqueness.
	\proofpart of boundness \label{req:boundness}

	For the triangle inequality and integral properties, we have that
	$$ |A(t)| \le |a(t)| + \int\limits_0^{t}|a(t-x)| \cdot dM(x) $$

	We can easily assess this upper buond for the value of $A(t)$, that proves our thesis.
	\begin{equation}\begin{split}
		\sup_{0\le t \le T} |A(t)| & \le \sup_{0\le t \le T} |a(t)| + \int\limits_0^{T}\sup_{0\le \eta \le T}|a(\eta)| \cdot dM(x) \\
		& = \sup_{0\le t \le T} |a(t)| \cdot [ 1+M(T) ] < \infty \text{ as }
		\begin{cases}
			|a(t)| \text{ is bounded for hypothesis} \\
			M(t) < \infty \text{ for } t<\infty
		\end{cases}
	\end{split}\end{equation}

	\proofpart of existence

		We will now assess that our guess is actually a valid solution obtaining \ref{eq:renewal_equation} from \ref{eq:renewal_solution}.

		\begin{equation}\begin{split}
			A(t) &= a(t) + M \ast a(t) = a(t) + \left(\sum\limits_{k=1}^{+\infty} F_k \right) \ast a(t) = \\
			&= a(t) + F \ast a(t) +\left(\sum\limits_{k=2}^{+\infty} F_k \right) \ast a(t) = \\
			&= a(t) + F \ast a(t) +\left(\sum\limits_{k=2}^{+\infty} F \ast F_{k-1} \right) \ast a(t) = \\
			&= a(t) + F \ast \left[ a(t) + \left(\sum\limits_{k=1}^{+\infty} F_k \right) \ast a(t) \right] = \\
			&= a(t) + F \ast \left[ a(t) + M(t) \ast a(t) \right] = \\
			&=a(t) + F \ast A ~ (t)
		\end{split}\end{equation}

	\proofpart of uniqueness

	This proof is the inverse reasoning of the proof of existence, as we will obtain \ref{eq:renewal_solution} from \ref{eq:renewal_equation}.

	\begin{equation}\begin{split}
		A(t) &= a(t) + F \ast A(t) \quad \text{which is a recursive expression.} \\
		&= a(t) + F \ast \left[a(t) + F \ast a(t) \right] = a(t) + F \ast a ~ (t) + F_2 \ast a(t) \\
		&= a(t) + F \ast a ~ (t) + F_2 \ast \left[a(t) + F \ast a(t) \right] \\
		&= a(t) + F \ast a(t) + F_2 \ast a(t) + F_3 \ast a(t) = \dots  = \\
		&= a(t) + \left( \sum\limits_{k=1}^{n-1}F_k\right) \ast a(t) + F_n \ast a(t) \\
	\end{split} \end{equation}

	For $n \to +\infty$, the term between parenthesis becomes $M(t)$, for its definition.
	\begin{equation}
		A(t) = a(t) + M \ast a(t) + \lim_{n \to +\infty} F_n \ast a(t)
	\end{equation}

	For our proof we will show that the remaining limit goes to zero.
	\begin{equation} \begin{split}
		|F_n \ast a(t)| & = \left| \int\limits_0^{t}A(t-\eta) \cdot dF_n(\eta) \right| \le \\
		& \le \int\limits_0^{t}|A(t-\eta)| \cdot dF_n(\eta) \le \sup\limits_{0 \le \eta \le t} |A(\eta)| \cdot F_n (t)
	\end{split}\end{equation}

	But, since $A(\eta)$ is bounded (see part \ref{req:boundness}) and $F_n(t)$ is infinitesimal in $n$, the proof is completed.
\end{proof}

\section{Wald's equation}

Let's now apply the renewal equation to another relevant quantity of a renewal process: we focus on the expectation of the next arrival time after a given time $t$.
	$$ S_{N(t) + 1} = \sum\limits_{i=1}^{N(t)+1}X_i $$

% \begin{equation}
% 	\exp[S_{N(t)+1}] = \exp\left[\sum\limits_{i=1}^{N(t)+1}X_i\right] = \exp[N(t)+1]\cdot \exp[X]\exp[S_{N(t)}] \neq \exp[N(t)]\cdot \exp[X]
% \end{equation}

This resembles a random sum, but it is not the case, since $N(t) + 1$ is not independent on the various $X_i$.

With the knowledge acquired on renewal processes, we try to answer this question applying the renewal argument on $ A(t) = S_{N(t)+1} $, differentiating again between times $t$ before and after first event.

\begin{equation}\begin{split}
	\exp[A(t)|X_1=x] &=
	\begin{cases}
		x & x>t \\
		x + A(t-x) & x \le t
	\end{cases}
\end{split} \end{equation}

Thus we can build a renewal equation.

\begin{equation} \begin{split}
	A(t) &= \int\limits_0^{+\infty} \exp[S_{N(t)+1}|X_1 = x] \cdot dF(x) \\
	&= \int\limits_0^{t} [x+ A(t-x)] \cdot dF(x) + \int\limits_t^{+\infty} x \cdot dF(x) \\
	&= \int\limits_0^{+\infty} x \cdot dF(x) + \int\limits_0^{t} A(t-x) \cdot dF(x) \\
	&= \exp[X_1] + \int\limits_0^{t} A(t-x) \cdot dF(x)\\
\end{split}\end{equation}

As proved earlier, the final solution for $A(t)$ is
$$ \exp[S_{N(t)+1}] = A(t) = \exp[X_1] + \int\limits_0^{t} \exp[X_1] \cdot dM(x) = \exp[X_1]\cdot [1+M(t)] $$
where the expectation is bounded if $\exp[X_1]$ is finite.

This is the same result we would have obtained with the formula of the random sum: this gives us the idea of extending random sums theory with the concept of \emph{stopping time}.

\begin{definition}[Stopping Time]
An integer random variable N is called \gls{st} for the i.i.d. sequence $X_i$ if
\begin{equation}
	\forall i > n, \{N=n\} \text{ is independent of }X_i
\end{equation}

Less formally, N is independent on what happens after $X_n$.
\end{definition}

\begin{theorem}[Wald's equation]
	Let $X_1, X_2, \dots, X_N $ be an i.i.d. sequence with finite mean and N a stopping time such that $\exp[N] < \infty$. Then

	\begin{equation}
		\exp\left[\sum\limits_{n=1}^N X_n \right] = \exp[N] \cdot \exp[X]
	\end{equation}
\end{theorem}
---
\begin{proof}
	We are gonna use a trick that will allow us to write the random sum as an infinite sum. \\

	Let $I_n = \begin{cases} 1 & N \ge n \\ 0 & N<n \end{cases}$~, we can observe immediatly that
	$$ \{I_n=1\} = \{N \ge n \} = \bigcap\limits_{i=1}^{n-1}\{ N \neq i \} \implies \{I_n=1\} \perp X_n, X_{n+1}, \ldots $$

	% it is independent on the future of $X$ after $n$.
	Now the proof of the thesis is straightforward.
	\begin{equation}\begin{split}
		\exp\left[\sum\limits_{n=1}^{N}X_n\right] &= \exp\left[\sum\limits_{n=1}^{N}X_n \cdot I_n \right] \stackrel{(1)}{=} \sum\limits_{n=1}^{+\infty}\exp[X_n \cdot I_n] \stackrel{(2)}{=} \\
		&=\sum\limits_{n=1}^{+\infty}\exp[X_n] \cdot \exp[I_n] \stackrel{(3)}{=} \exp[X]\cdot\sum\limits_{n=1}^{+\infty}\exp[I_n] \stackrel{(4)}{=} \\
		&= \exp[X] \cdot \sum\limits_{n=1}^{+\infty}\prob[N \ge n] = \exp[X] \cdot \exp[N]
	\end{split}\end{equation}
	where
	\begin{itemize}
		\item[(1)] holds since the sum converges always, since it is actually a finite one
		\item[(2)] holds for the indipendence between $I_n$ and $X_n$
		\item[(3)] is due to the identically distributed $X_k$
		\item[(4)] holds for $I_n$ definition
	\end{itemize}
\end{proof}

\subsection{Examples}
	\begin{enumerate}
		\item Given $\prob[X_i=0]=\prob[X_i = 1] = \frac{1}{2}$, $N = \min\{n : X_1 + \dots + X_N =10\}$ is a \gls{st}, and in particular
		$10 = \exp[N] \cdot \exp[X] = 0.5 \cdot \exp[N] \implies \exp[N]=20$
		\item Given $\prob[X_i=-1]=\prob[X_i = 1] = \frac{1}{2}$, $N = \min\{n : X_1 + X_2 + \dots + X_N =1\}$ is a \gls{st}, but the expected stop time
		is $1 = \exp[N] \cdot \exp[X] = 0 \cdot \exp[N] \implies $ ABSURD. We conclude that Wald's equation doesn't apply. So it must be that N has not finite mean $\implies \exp[N]=+\infty$
	\end{enumerate}

\section{The key renewal theorem}
\begin{definition}
	(Point of increase) Given a distribution function F we call \textit{point of increase} every point $\alpha$ such that:
	\begin{equation}
		F(\alpha+\epsilon)-F(\alpha-\epsilon)>0 \quad  \forall \quad
		\epsilon > 0
	\end{equation}
\end{definition}
\begin{definition}
	(Arithmetic function) We say that a dristibution function F is \textit{arithmetic} if $\exists$ $\lambda > 0$ such that F has points of increase exclusively among the points 0, $\pm \lambda$, $\pm 2\lambda$, ... . \\
	We call \textit{SPAN} the largest $\lambda$ for which F is still arithmetic.
\end{definition}

The distribution function of a discrete random variable with possible values 0,1,2,... is an arithmetic function with SPAN=1.

\begin{definition}
	(Directly Riemann Integrable Function) Given a function g defined on [0, $\infty$) we define the following quantities for every $\delta > 0$:
	\begin{align*}
		\underline \sigma (\delta) = \delta \cdot \sum_{n=1}^{\infty} min\{g(t):(n-1)\delta \leq t \leq n \delta \}
		\\
		\bar \sigma (\delta) = \delta \cdot \sum_{n=1}^{\infty}max\{g(t):(n-1)\delta \leq t \leq n \delta \}
	\end{align*}
	We say that g is directly Riemann integrable if both $\underline \sigma (\delta)$ and $\bar \sigma (\delta)$ converge absolutely $\forall \quad \delta > 0$ and if:
	\begin{equation}
		\underline \sigma (\delta) - \bar \sigma (\delta) \rightarrow 0 \quad \delta \rightarrow 0
		\end{equation}
\end{definition}

We note that every function for which $\int_{0}^{\infty} |g(t)| dt$ < $\infty$ (g is absolutely integrable) is directly Riemann integrable.

\begin{theorem}
	(Key Renewal Theorem) Is given a distribution function F of a positive random variable $a$ with mean $\mu$. We suppone that $a$ is directly Riemann integrable and that $A$ is the solution of the \textit{renewal equation}
	\begin{equation}
		A(t)=a(t)+\int_{0}^{t}A(t-x)dF(x)
	\end{equation}
	If F is not arithmetic, then:
	\begin{equation*}
		\lim_{t \rightarrow \infty} A(t) =
		\begin{cases}
			\frac{1}{\mu} \int_{0}^{\infty}a(x)dx \quad & if \quad \mu < \infty
			\\
			0 \quad & if \quad \mu = \infty
		\end{cases}
	\end{equation*}
	If F is arithmetic with SPAN = $\lambda$ then $\forall c > 0$:
	\begin{equation*}
		\lim_{t \rightarrow \infty} A(c+n\cdot \lambda) =
		\begin{cases}
			\frac{\lambda}{\mu} \sum_{n=0}^{\infty}a(c+n \cdot \lambda) \quad & if 	\quad \mu<\infty
			\\
			0 \quad & if \quad \mu = \infty
		\end{cases}
	\end{equation*}
\label{KRT1}
\end{theorem}

The theorem \ref{KRT1} can be also expressed in the following form:

\begin{theorem}
	(Key renewal theorem) Is given a distribution function F of a positive random variable with mean $\mu$. We suppone $h>0$ and that $M(t)=\sum_{k=1}^\infty F_{k}(t)$ is the \textit{renewal function} associated with F.
	If F is not arithmetic then:
	\begin{equation}
		\lim_{t \rightarrow \infty} [M(t+h)-M(t)]=\frac{h}{\mu}
	\end{equation}
	If F is arithmetic with SPAN = $\lambda$ then:
	\begin{equation}
		\lim_{t \rightarrow \infty} [M(t+h)-M(t)]=\frac{h}{\mu} \quad \forall h = n \cdot \lambda
	\end{equation}
	\label{KRT2}
\end{theorem}

We note that the \textit{elementary renewal theorem} $\lim_{t \to \infty} \frac{1}{t} M(t) = \frac{1}{\mu}$ is a corollary of the \textit{key renewal theorem} \ref{KRT2}.

\subsection{Application of the key renewal theorem}

\paragraph{Limiting distribution of the excess life}

We say that $\gamma_{t}=S_{N(t)+1}-t$ is the excess life at time t and that $A_z=Prob[\gamma_t>z]$ for a fixed $z>0$. We obtain that:
\begin{equation*}
	Prob[\gamma_t>z|X_1=x] = \begin{cases}
		1 \quad & if \quad x > t+z \\
		0 \quad & if \quad t+x \geq x > t \\
		A_z(t-x) \quad & if \quad t \geq x > 0
	\end{cases}
\end{equation*}
For the law of the total probability we obtain that:
\begin{align*}
	A_z(t)= & \int_{0}^{\infty} Prob[\gamma_t>z|X_1=x] dF(x) = \int_{0}^{t}A_z(t-x)dF(x)+\int_{t+z}^{\infty}dF(x)= \\ & \int_{0}^{t}A_z(t-x)dF(x)+1-F(t+z)
\end{align*}
For the \textit{renewal equation} $ A(t)=a(t)+\int_{0}^{t}A(t-x)dF(x)=a(t)+\int_{0}^{t}a(t-x)dM(x) $ we conclude that:
\begin{align*}
	& a(t) = 1 - F(t+z) \\
	& A_z(t)=\int_{0}^{t}(1-F(t+z-x))dM(x)+1-F(t+z) \\
	& \int_{0}^{\infty} a(x) d(x) = \int_{0}^{\infty}(1-F(x)) d(x) = \int_{z}^{\infty}(1-F(y))dy \leq \int_{0}^{\infty}(1-F(y))dy = \mu
\end{align*}
We suppone $\mu < \infty$. For the \textit{renewal theorem} we obtain that:
\begin{equation}
	\lim_{t \rightarrow \infty} Prob[\gamma_t>z] = \lim_{t \rightarrow \infty} A_z(t) = \frac{1}{\mu} \cdot \int_z^{\infty}(1-F(x))dx \quad \forall z > 0
	\label{limitingdistribution}
\end{equation}

From \ref{limitingdistribution} we can determine the limiting distribution for the \textit{current life} $\delta_t$ and for the \textit{total life} $\beta_t$. First we note that:
\begin{equation}
	\{\gamma_t \geq x, \delta_t \geq y \} \Leftrightarrow \{\gamma_{t-y} \geq x+y \}
	\label{currtotallife}
\end{equation}
From \ref{currtotallife} we have that:
\begin{align*}
	\lim_{t \rightarrow \infty} Prob[\delta_t \geq y, \gamma_t \geq x] & = \lim_{t \rightarrow \infty} Prob[\gamma_{t-y} \geq x+y] \\ & = \frac{1}{\mu} \cdot \int_z^{\infty}(1-F(z))dz
\end{align*}
In particular we have that:
\begin{align*}
	\lim_{t \rightarrow \infty} Prob[\delta_t \geq y] & = \lim_{t \rightarrow \infty} Prob[\delta_t \geq y, \gamma_{t} \geq 0] \\ & = \frac{1}{\mu} \cdot \int_z^{\infty}(1-F(z))dz
\end{align*}
$\frac{1-F(z)}{\mu}$ is the probability density function of $\delta_t$. We are able to compute $\delta_t$ and $\gamma_t$ averages.
\begin{align*}
	\exp[\delta_t]=\exp[\gamma_t] & =\int_z^{\infty} \frac{z}{\mu} \cdot (1-F(z))dz \\ & = \frac{z^2}{2\mu}(1-F(z))|_0^{\infty}+\int_0^{\infty}\frac{z^2}{2 \mu} f(z)dz= \frac{\exp[X^2]}{2 \exp[X]}
\end{align*}
Finally we conclude that:
\begin{align}
	& \exp[\delta_t] = \frac{\exp[X^2]}{2 \exp[X]}
	\\ & \exp[\gamma_t] = \frac{\exp[X^2]}{2 \exp[X]}
	\\ & \exp[\beta_t] = \frac{\exp[X^2]}{\exp[X]}
\end{align}

\paragraph{Asymptotic expansion of the renewal function}

Given a distribution function of mean $\mu$ and variance $\sigma$ we want to prove that $\lim_{t \rightarrow \infty} (M(t) - \frac{t}{\mu}) = \frac{\sigma^2-\mu^2}{2\mu^2}$. For $t \rightarrow \infty$ we have what follows:
\begin{align*}
	M(t)-\frac{t}{\mu} & =\exp[N(t)+1]-\frac{t}{\mu}-1 \\
	& = \frac{1}{\mu} \cdot (\exp[S_{N(t)+1}]-t)-1 \\
	& = \frac{1}{\mu} \cdot \exp[\delta_t]-1 \\
	& = \frac{1}{\mu}\frac{\exp[X^2]}{2\mu}-1 \\
	& = \frac{\sigma^2+\mu^2}{2\mu^2}-1 \\
	& = \frac{\sigma^2-\mu^2}{2\mu^2}
\end{align*}
Then we conclude that:
\begin{equation}
	\lim_{t \rightarrow \infty} (M(t) - \frac{t}{\mu}) = \frac{\sigma^2-\mu^2}{2\mu^2}
\end{equation}

\subsection{Delayed renewal processes}

We assume that $\{X_k\}$ are independent positive random variables but only $X_2,X_3,...$ are identically distribuited. $X_1$ has a distribution function G that differs from the distribution function F of the other variables. We call such process \textit{delayed renewal process}. Given an ordinary renewal process we can obtain a \textit{delayed renewal process} if we fix the time origin $t=0$ a certain time after the start of the ordinary process. We put $S_0=0$ and $S_n=X_1+X_2+...+X_n$ and $N(t)$ equal to the number of renewal at time t. We must distinguish between the mean number of renewals in the delayed process $M_D(t)$ and the renewal function associated with F $M(t)$.
\begin{align}
	& M_D(t) = \exp[N(t)]
	\\ & M(t) = \sum_{k=1}^{\infty}F_k(t)
\end{align}
Now we want to prove what follows:
\begin{align*}
	& \lim_{t \to \infty }\frac{M_D(t)}{t}=\frac{1}{\mu}
	\\ & \lim_{t \to \infty }[M_D(t)-M_D(t-d)]=\frac{d}{\mu}
\end{align*}

We have already seen that for a recurrent irreducible aperiodic Markov Chain the following statament is true.
\begin{equation}
	\lim_{n \to \infty} P_{jj}^{(n)}=\pi_j=\frac{1}{m_j}=\frac{1}{\sum_{n=1}^{\infty}n \cdot f_{jj}^{(n)}}
\end{equation}
Given a reccurent state $j$ we call $N_j(t)$ the number of visits in j by the time t. The following statament is always true for any initial state $Y_0$.
\begin{equation}
	N_j(n)-N_j(n-1)=1 \quad \Leftrightarrow \quad Y_n=j
\end{equation}
If $Y_0$ is equal to j, then $N_j$ is a ordinary renewal process. We keep $Y_0=j$ and we obtain what follows.
\begin{align*}
	& \exp[N_j(n)-N_j(n-1)|Y_0=j]=M(n)-M(n-1)=P_{jj}^{(n)}
	\\ & \Rightarrow \pi_j=\frac{1}{m_j}=\lim_{n \to \infty} P_{jj}^{n} = \lim_{n \to \infty} [M(n)-M(n-1)]=\frac{1}{\mu}
\end{align*}
So we have proved that:
\begin{equation}
	\lim_{n \to \infty} P_{jj}^{n}=\frac{1}{\mu}
\end{equation}
If $Y_0=i \neq j$, then $N_j(n)$ is a delayed renewal process. We keep $Y_0=i \neq j$ and we obtain what follows.
\begin{align*}
	& \exp[N_j(n)-N_j(n-1)|Y_0=i \neq j]=M_D(n)-M_D(n-1)=P_{jj}^{(n)}
	\\ & \Rightarrow \frac{1}{\mu}=\lim_{n \to \infty} P_{jj}^{n} = \lim_{n \to \infty} [M_D(n)-M_D(n-1)]
\end{align*}
So we have proved that:
\begin{equation}
	\lim_{n \to \infty} [M_D(n)-M_D(n-1)]=\frac{1}{\mu} \Rightarrow \lim_{t \to \infty }\frac{M_D(t)}{t}=\frac{1}{\mu}
\end{equation}
Now we consider a periodic Markov Chain with period $d$. We define $N_j$ as before. The following statament is always true for any initial state $Y_0$.
\begin{equation}
	N_j(n \cdot d)-N_j((n-1)\cdot d)=1 \quad \Leftrightarrow \quad Y_{n \cdot d}=j
\end{equation}
For $Y_0=j$ we obtain what follows.
\begin{align*}
	& \exp[N_j(n \cdot d)-N_j((n-1)\cdot d)|Y_0=j]=M(n \cdot d)-M((n-1)\cdot d)=P_{jj}^{(n \cdot d)}
	\\ & \Rightarrow d \cdot \pi_j=\frac{d}{m_j}=\lim_{n \to \infty} P_{jj}^{n \cdot d} = \lim_{n \to \infty} [ M(n \cdot d)- M( (n-1) \cdot d)]=\frac{d}{\mu}
\end{align*}
So we have proved that:
\begin{equation}
	\lim_{n \to \infty} P_{jj}^{n \cdot d}=\frac{d}{\mu}
\end{equation}
For $Y_0 \neq j$ we obtain what follows.
\begin{align*}
	& \exp[N_j(n \cdot d)-N_j((n-1) \cdot d)|Y_0=i \neq j]=M_D(n \cdot d)-M_D((n-1) \cdot d)=P_{jj}^{(n \cdot d)}
	\\ & \Rightarrow \frac{d}{\mu}=\lim_{n \to \infty} P_{jj}^{n \cdot d} = \lim_{n \to \infty} [M_D(n \cdot d)-M_D((n-1) \cdot d)]
\end{align*}
So we have proved that:
\begin{equation}
	\lim_{n \to \infty} [M_D(n \cdot d)-M_D((n-1) \cdot d)]=\frac{d}{\mu} \Rightarrow \lim_{t \to \infty }[M_D(t)-M_D(t-d)]=\frac{d}{\mu}
\end{equation}

\subsection{Cumulative and related renewal process}
We associate to every random varriable $X_i$ a second random variable $Y_i$. So $Y_i$ and $X_i$ are dependent but $(X_i,Y_i)$ and $(X_j,Y_j)$ are independent. We call F the distribution function of $X_i$, G the distribution function of $Y_i$, $\mu$ the mean of $X_i$ and $\nu$ the mean of $Y_i$.
\paragraph{Queueieng model}
Suppose to have queueing system in which the arrivals follow a Poisson process. $X_i$ represents the the period between two consequent arrivals. $Y_i$ is a portion $X_i$ and represents the period in which the queieng system is busy. We call $p(t)$ the probability that t falls into some portion $Y_i$. We suppone that the first interval has length $X_1=x$ and we obtain what follows.
\begin{align*}
	p(t) & =Prob[t \in Y |X_1 = x]=\begin{cases}
		Prob[Y_1>t|X_1=x] \quad & if \quad x \geq t
		\\ p(t-x) \quad & if \quad x<t
	\end{cases}
	\\ & = \int_0^t p(t-x)dF(x)+\int_t^{\infty}Prob[Y_1>t|X_1=x]dF(x)
\end{align*}
Knowing that $\int_0^{t}Prob[Y_1>t|X_1=x]dF(x)=0$ we have that:
\begin{align*}
	p(t) & = \int_0^t p(t-x)dF(x)+\int_0^{\infty}Prob[Y_1>t|X_1=x]dF(x)
	\\ & = Prob[Y_1>t]+\int_0^t p(t-x)dF(x)
\end{align*}
We know that $p(t)= Prob[Y_1>t]+\int_0^t p(t-x)dF(x)$ is a renewal equation. We can establish that $\int_0^{\infty}Prob[Y_1>t]dt=\exp[Y_1]=\nu$. Applying the renewal theorem we obtain what follows.
\begin{align*}
	\lim_{t \to \infty} p(t) & = \frac{1}{\mu}\cdot\int_0^{\infty}p(t)dt = \frac{\nu}{\mu}= \frac{\exp[X]}{\exp[Y]}
\end{align*}

\section{Reward Processes}

Consider a \textit{renewal process} $N(t)$ with interarrival time $X_n$ with distribution function $F$. We suppone that each time a renewal occurs we receive a \textit{reward}; we call $R_n$ the reward associated with the nth renewal event. We suppone that each reward $R_n$ depend on the length of the interval $X_n$. In this scenario the pairs $(X_n, R_n)$ are independent and identically distribuited. We define the total number of reward at time $t$ $R(t)$ as follows.
\begin{equation}
	R(t)=\sum_{n=1}^{N(t)}R_n
\end{equation}
Now we adopt the following definitions.
\begin{align*}
	\exp[X] & =\exp[X_n]
	\\ \exp[R] & =\exp[R_n]
\end{align*}
\begin{theorem}[Th. 3.6 (Ross)]
  If $\exp[X]<\infty$ and $\exp[R]<\infty$ then with probability equal to 1 we have:
	\begin{equation}
		\lim_{t \to \infty}\frac{R(t)}{t}=\frac{\exp[R]}{\exp[X]}
		\label{rewardtheorem1}
	\end{equation}
	\begin{equation}
		\lim_{t \to \infty}\frac{\exp[R(t)]}{t}=\frac{\exp[R]}{\exp[X]}
		\label{rewardtheorem2}
	\end{equation}
\end{theorem}
\begin{proof}
	We want to prove \ref{rewardtheorem1}.
	\begin{align*}
		\frac{R(t)}{t}=\frac{\sum_{n=1}^{N(t)}R_n}{t}= \bigg( \frac{\sum_{n=1}^{N(t)}R_n}{N(t)}\bigg)\cdot\bigg(\frac{N(t)}{t}\bigg)
	\end{align*}
	By the strong law of large numbers we obtain that:
	\begin{align*}
		\lim_{t \to \infty}\frac{\sum_{n=1}^{N(t)}R_n}{N(t)}=\exp[R]
	\end{align*}
	By the renewal theorem we obtain that:
	\begin{align*}
		\lim_{t \to \infty}=\frac{1}{\exp[X]}
	\end{align*}
	Then \ref{rewardtheorem1} is proven.
\end{proof}
\begin{proof}
	We want prove \ref{rewardtheorem2}. We note immediately that $N(t)+1$ is a stopping time both for $X_1,X_2,X_3,...$ and for $R_1,R_2,R_3,..$.
	\begin{align*}
		\sum_{n=1}^{N(t)}R_n \leq R(t) \leq \sum_{n=1}^{N(t)+1}R_n
	\end{align*}
	Then we have that:
	\begin{align*}
		& \exp\bigg[\sum_{n=1}^{N(t)}R_n\bigg] \leq \exp[R(t)] \leq \exp\bigg[\sum_{n=1}^{N(t)+1}R_n\bigg]
		\\ & (M(t)+1)\exp[R]-\exp[R_{N(t)+1}] \leq \exp[R(t)] \leq (M(t)+1)\exp[R]
	\end{align*}
	Then, knowing that $\lim_{t \to \infty} \frac{(M(t)+1)\exp[R]}{t} = \frac {\exp[R]}{\exp[X]} $ we have that:
	\begin{align*}
		\frac {\exp[R]}{\exp[X]} - \lim_{t \to \infty} \frac{\exp[R_{N(t)+1}]}{t} \leq \lim_{t \to \infty} \frac{\exp[R(t)]}{t} \leq \frac{\exp[R]}{\exp[X]}
	\end{align*}
	We put $A(t)=\exp[R_{N(t)+1}]$ and we have that:
	\begin{align*}
		& \exp[R_{N(t)+1}|X_1=x]=
			\begin{cases}
				\exp[R_1|X_1=x] \quad & if \quad x>t
				\\ A(t-x) \quad & if \quad x \leq t
			\end{cases}
		\\ & \Rightarrow
		\\ & A(t)=\int_{0}^{t}A(t-x)dF(x)+\int_{t}^{+\infty}\exp[R_1|X_1=x]dF(x)
	\end{align*}
	We put $a(t)=\int_{t}^{+\infty}\exp[R_1|X_1=x]dF(x)$ and we have that:
	\begin{align*}
		A(t)=\int_{0}^{t}a(t-x)dM(x)+a(t)=(M \ast a) (t)+a(t)
	\end{align*}
	Assuming that $R_n \geq 0$ we have that:
	\begin{align*}
		& \lim_{t \to \infty}a(t) = \lim_{t \to \infty}\int_{t}^{+\infty}\exp[R_1|X_1=x]dF(x)=0
		\\ & a(0)=\int_{0}^{+\infty}\exp[R_1|X_1=x]dF(x)=\exp[R_1]<+\infty
	\end{align*}
	\begin{align*}
		|a(t)| & \leq \int_{t}^{+\infty}\exp[|R_1||X_1=x]dF(x)
		\\ & \leq \int_{0}^{+\infty}\exp[|R_1||X_1=x]dF(x) = \exp[|R_1|]=\exp[R_1]<+\infty
	\end{align*}
	So we have come to the following results:
	\begin{align*}
		1) \quad & \forall \epsilon>0 \quad \exists T>0:\quad |a(t)|<\epsilon \quad \forall t>T
		\\ 2) \quad & |a(t)| \leq \exp[|R_1|]<+\infty \quad \forall t
	\end{align*}
	Knowing that $A(t)=\int_{0}^{t}a(t-x)dM(x)+a(t)$ we have that:
	\begin{align*}
		|A(t)| & = |\int_{0}^{t}a(t-x)dM(x)+a(t)| \leq \int_{0}^{t}|a(t-x)|dM(x)+|a(t)|
		\\ & \leq \int_{0}^{t-T}|a(t-x)|dM(x)+ \int_{t-T}^{t}|a(t-x)|dM(x) + a(t)
		\\ & \leq \int_{0}^{t-T}\epsilon dM(x)+ \int_{t-T}^{t}\exp[|R_1|] dM(x) + a(t)
	\end{align*}
	\begin{align*}
		\lim_{t \to \infty} \frac{A(t)}{t} \leq \lim_{t \to \infty} \epsilon \cdot \frac{M(t-T)}{t} + \lim_{t \to \infty} \exp[|R_1|]\cdot \frac{M(t)-M(t-T)}{t} + \lim_{t \to \infty} \frac{a(t)}{t}
	\end{align*}
	Knowing that $\lim_{t \to \infty} \epsilon \cdot \frac{M(t-T)}{t}=\frac{\epsilon}{\exp[X]}$, $\lim_{t \to \infty} \exp[|R_1|]\cdot \frac{M(t)-M(t-T)}{t}=0$ and $\lim_{t \to \infty} \frac{a(t)}{t}=0$ we have that:
	\begin{align*}
		\lim_{t \to \infty} \frac{A(t)}{t} \leq \frac{\epsilon}{\exp[X]} \Rightarrow \lim_{t \to \infty} \frac{\exp[R_{N(t)+1}]}{t}=0 \Rightarrow \frac {\exp[R]}{\exp[X]} \leq \lim_{t \to \infty} \frac{\exp[R(t)]}{t} \leq \frac{\exp[R]}{\exp[X]}
	\end{align*}
	The we have that:
	\begin{align*}
		\lim_{t \to \infty} \frac{\exp[R(t)]}{t} = \frac{\exp[R]}{\exp[X]}
	\end{align*}
	Then \ref{rewardtheorem2} is proven.
\end{proof}

\section{Regenerative Processes}

Consider a stochastic process $\{X(t), t \geq 0\}$ with state space$\{0, 1, 2, ... \}$ having
the property that there exist time points at which the process (probabilistically) restarts itself. That is, suppose that with probability 1, there exists a time $S_1$
such that the continuation of the process beyond $S_1$ is a probabilistic replica
of the whole process starting at 0. Note that this property implies the existence
of further times $S_2 , S_3 , \dots$ having the same property as $S_1$. Such a stochastic
process is known as a \emph{regenerative process}.
From the above, it follows that $\{S_1 , S_2 , ...\}$ constitute the event times of
a renewal process. We say that a cycle is completed every time a renewal
occurs. Let $N(t) = \max\{n: S_n \leq t\}$ denote the number of cycles by time t.

\section{Semi-Markov Processes}
A semi-Markov process is one that changes states in accordance with a Markov
chain but takes a random amount of time between changes. More specifically
consider a stochastic process with states $0, 1, ...  $, which is such that, whenever
it enters state $i, i\geq 0$:
\begin{enumerate}
	\item The next state is $j$ with probability $P_{ij}$
	\item Given that the next state is $j$, the time the transition takes is random with distribution $F_{ij}$ and independent of past and future
\end{enumerate}
If we let $Z(t)$ denote the state at time $t$, then $\{Z(t), t\leq 0\}$ is called a \emph{semi-Markov
process}.
Thus a semi-Markov process does not possess the Markovian property that
given the present state the future is independent of the past. For in predicting
the future not only would we want to know the present state, but also the
length of time that has been spent in that state\footnote{note that ``$Z(t) = \mbox{ state of the process at time } t$" is Markov only in the case where the distribution pdf od the transition time is memoryless (for example exponential), more in general $Z(t)$ is not Markovian.}. Of course, at the moment of transition, all we would need to know is the new state ( and nothing about
the past). %A Markov chain is a semi-Markov process in which

Let $H_i(t)$ denote the \emph{distribution of time} that the semi-Markov process spends
in state i before making a transition. That is, by conditioning on the next
state, we see
	\begin{equation}
		H_i(t) = \sum_j P_{ij} F_{ij}(t)
	\end{equation}

and let $\mu_i$ denote its mean. That is:
	\begin{equation}
		 \mu_i = \exp[H_i(t)] = \int_{0}^{+\infty}x \,dH_i(x)
	\end{equation}

\begin{definition}[Average return time]
	$\mu_{ii} = $ average time between two consecutive transition in state $i$
\end{definition}

\subsection{Regenerative Processes}

Consider a stochastic process $\{X(t), t \geq 0\}$ with state space$\{0, 1, 2, ... \}$ having
the property that there exist time points at which the process (probabilistically) restarts itself. That is, suppose that with probability 1, there exists a time $S_1$
such that the continuation of the process beyond $S_1$ is a probabilistic replica
of the whole process starting at 0. Note that this property implies the existence
of further times $S_2 , S_3 , \dots$ having the same property as $S_1$. Such a stochastic
process is known as a \emph{regenerative process}.
From the above, it follows that $\{S_1 , S_2 , ...\}$ constitute the event times of
a renewal process. We say that a cycle is completed every time a renewal
occurs. Let $N(t) = \max\{n: S_n \leq t\}$ denote the number of cycles by time t.

\subsection{Semi-Markov Processes}
A semi-Markov process is one that changes states in accordance with a Markov
chain but takes a random amount of time between changes. More specifically
consider a stochastic process with states $0, 1, ...  $, which is such that, whenever
it enters state $i, i\geq 0$:
\begin{enumerate}
	\item The next state is $j$ with probability $P_{ij}$
	\item Given that the next state is $j$, the time the transition takes is random with distribution $F_{ij}$ and independent of past and future
\end{enumerate}
If we let $Z(t)$ denote the state at time $t$, then $\{Z(t), t\leq 0\}$ is called a \emph{semi-Markov
	process}.
Thus a semi-Markov process does not possess the Markovian property that
given the present state the future is independent of the past. For in predicting
the future not only would we want to know the present state, but also the
length of time that has been spent in that state\footnote{note that ``$Z(t) = \mbox{ state of the process at time } t$" is Markov only in the case where the distribution pdf od the transition time is memoryless (for example exponential), more in general $Z(t)$ is not Markovian.}. Of course, at the moment of transition, all we would need to know is the new state ( and nothing about
the past). %A Markov chain is a semi-Markov process in which

Let $H_i(t)$ denote the \emph{distribution of time} that the semi-Markov process spends
in state i before making a transition. That is, by conditioning on the next
state, we see
\begin{equation}
H_i(t) = \sum_j P_{ij} F_{ij}(t)
\end{equation}

and let $\mu_i$ denote its mean. That is:
\begin{equation}
\mu_i = \exp[H_i(t)] = \int_{0}^{+\infty}x \,dH_i(x)
\end{equation}

Let $T_{ii}$ denote the time between successive transitions into state i and let
\begin{equation}
\mu_{ii}=\exp [T_{ii}]
\end{equation}
By using the theory of alternating renewal processes, it is a
simple matter to derive an expression for the limiting probabilities of a semi-Markov
process.

\begin{theorem}
	If the semi-Markov process is irreducible and if $T_{ii}$ has a non-lattice\footnote{boh} distribution with finite mean, then

	$$P_j = \lim_{t \to \infty} \prob[Z(t)=j | Z(0)=k]$$

	Exists and independent of the initial state. Furthermore,

	$$P_j = \frac{\exp[\mbox{time in state i in a cycle}]}{\exp[\mbox{duration of the cycle}]} = \frac{\mu_i}{\mu_{ii}}$$

\end{theorem}
Note that while $\mu_i$ is easy to compute, $\mu_{ii}$ is much more difficult.

\subsection{Renewal-Reward processes}

Let:

\begin{equation}
r_{ij} = \mbox{reward of transition } i\rightarrow j. \qquad R_{ij} = \exp[r_i]
\end{equation}
\begin{equation}
R_i = \sum_k P_{ik} R_{ik} = \mbox{ average reward of a visit to state } i
\end{equation}
$\theta_{ij} = $ total reward of going from i to j for the first time following any path
\begin{equation}
\theta_{ij} = \begin{cases}
&r_{ij} \quad\mbox{with probability } P_{ij}\\
&r_{ik}+\theta_{kj}  \quad\mbox{with probability } P_{ik}, k\neq j
\end{cases}
\end{equation}
\begin{equation*}
\rho_{ij} = \exp[\theta_{ij}] = \sum_{k=0}^{\infty}\exp[\theta_{ij}| X_1=k] P_{ik} = R_{ij}P_{ij} +\sum_{k \neq j} P_{ik} [R_{ik}+\rho_{kj}] = R_i + \sum_{k \neq j}P_{ik}\rho_{kj}
\end{equation*}

\begin{equation}
\Rightarrow\rho_{ij} = \exp[\theta_{ij}] =  R_i + \sum_{k \neq j}P_{ik}\rho_{kj}
\end{equation}


We have that:
\begin{equation*}
\sum_i \pi_i \rho_{ij} = \sum_i \pi_i R_i + \sum_i \sum_{k \neq j} \pi_i P_{ik} \rho_{kj} = \sum_j \pi_i R_i + \sum_{k \neq j}\rho_{kj}\sum_i\pi_i P_{ik}
\end{equation*}
So we have that for \emph{any} metric $r(\cdot)$
\begin{equation}
\Rightarrow\sum_i \pi_i \rho_{ij} = \sum_j \pi_i R_i + \sum_{k \neq j}\pi_k\rho_{kj},\qquad \pi_j\rho_{jj} = \sum_i \pi_i R_i
\end{equation}
if the metric is \emph{time}
\begin{equation}
\pi_j \mu_{jj} = \sum_i \pi_i \mu_i
\end{equation}

Now, in system modeling one of the main task of performance evaluation is to find te average value of some reward over time, that is to evaluate $\lim_{t \to \infty}\frac{R(t)}{t}$. The following result applies:
\begin{equation}
\lim_{t \to \infty}\frac{R(t)}{t} = \frac{\exp[R]}{\exp[X]} = \frac{\rho_{jj}}{\mu_{jj}} = \frac{\sum_i \pi_i \frac{R_i}{\pi_j}}{\sum_i \pi_i \frac{\mu_i}{\pi_j}} = \frac{\sum_i \pi_i \sum_j P_{ik} R_{ik}}{\sum_i \pi_i \sum_k P_{ik}T_{ik}}
\end{equation}

This is a powerful way to evaluate systems performances, in order for this model to apply 2 conditions need to be met:
\begin{enumerate}
	\item The system must be able to be modeled with a concept of \emph{state}.\footnote{That's good for us, every protocol is essentially a state machine}
	\item The process have to be Markovian or at least semi-Markovian
\end{enumerate}
