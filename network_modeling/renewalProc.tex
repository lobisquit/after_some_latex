\chapter{Renewal Processes (Cap 7)}
The main idea of a renewal process is a cyclic recurrence of a random fenomena presenting always the same statistics. The classical example is the lifetime of a light bulb: everytime a light blub dies the lifetime of the new one have the same statistics as the first one.

A renewal process is a sequence of i.i.d. $r.v._s$ with the same statistical properties.
\#TODO Graph

where $N(t) = $ number of events in $(0;t] = max\{n : W_n \le t \}$ and $ S_n = W_n = \sum\limits_{k=1}^n X_k =$ time of the n-th renewal.
By knowing $N(t)$ or $W_n$ or $X_i$ allows to fully characterize the process.

\section{Assumptions}
$X_i$ is i.i.d. sequence of $r.v._s \sim F(x) = \prob[X_i \le x] \forall i \text{ with } F(\infty)=0$
(so the process always end and restart) and $F(0)=0$. Those two conditions implies that the renewal happen in a finite time and not at the same time.

We want to determine
$$\begin{cases}
	\exp[N(t)]=M(t) & \text{the renewal function} \\
	\prob[W_n \le x] = F_n(x) & \text{where } F_n(x) \text{ is the n-th convolution of $f$ by itself}
\end{cases}$$

\begin{equation}\begin{split} \noindent
	N(t)\ge k \quad &\iff W_k \le t\\
	\prob[W_k \le t] &= \prob[N(t) \ge k] = F_k(t) \\
	\text{In particular} \\
	\prob[N(t)=k] = F_k(t)-F_{k+1}(t)& \\
	M(t) = \exp[N(t)]=\sum\limits_{k=1}^{+\infty}\prob[N(t)\ge k] &\implies M(t)=\sum\limits_{k=1}^{+\infty}F_k(t)
\end{split}\end{equation}

We then define $\delta_t = t - W_{N(t)}$ the \textit{current life} (or age) and $\gamma_t = W_{N(t)+1}-t$ the \textit{residual lifetime}.
The total lifetime is defined as $\beta_t = \delta_t + \gamma_t$.

An application of the renewal process is a markov chain where starts of a busy period are renewal instances if and only if
the conditions are the same for each start instance, which happens as when the start period begin, the previous instant got the mc empty.
A departure, instead, happens after a full service time and after an arrival. This means that if the arrival is a generic process, the instance
can depend on previous arrivals, so the conditions at the beginning are not independent of the previous status and the conditions
for the statistical properties are not the same for each start.

\section{CASE: Poisson processes}
\begin{equation}
	\begin{split}
		F(x)=1-e^{-\lambda \cdot x} &\quad M(t)=\exp[N(t)]=\lambda \cdot t \quad \prob[N(t)=k]=\frac{(\lambda \cdot k)^k}{k!}\cdot e^{-\lambda \cdot t}\\
		\prob[\gamma_t > x]&=\prob\left[\text{no events in } (t,t+x] \right]=e^{-\lambda \cdot x} \implies \text{\textbf{memoryless}}\\
		\prob[\delta_t > x] &= \prob \left[\text{no events in }(t-x,t] \right]=
		\begin{cases}
			e^{-\lambda x} & \text{if } x < t \\
			0 & \text{if } x \ge t\\
		\end{cases}
	\end{split}
\end{equation}

\subsection{Joint distribution}
\begin{equation}
	\prob[\gamma_t > x, \delta_t > y ] =
	\begin{cases}
		e^{-\lambda \cdot (x+y)} & \text{if } y < t \\
		0 & \text{if } y \ge t \\
	\end{cases}
\end{equation}

For poisson processes residual and current life are independent, which is a consequence of the memoryless propriety. We defined $\beta_t=\gamma_t + \delta_t$, so
\begin{equation}\begin{split}
\exp[\beta_t]&=\exp[\gamma_t] + \exp[\delta_t] = \frac{1}{\lambda} + \exp[\delta_t]\\
\exp[\delta_t]&= \int_0^t e^{-\lambda \cdot x} dx = \frac{1-e^{-\lambda \cdot t}}{\lambda} \\
&\implies \exp[\beta_t]= \frac{2-e^{-\lambda \cdot t}}{\lambda}
\end{split}\end{equation}
\textbf{\textsc{Paradox: (I don't think this is the real paradox)}}
\begin{equation}
	\begin{split}
		\prob[\gamma_t > x] &\approx \prob[\delta_t>x] = e^{-\lambda \cdot t} \quad \text{for }x<t \\
		\text{but } &\prob[\delta_t >x , \gamma _ t > y ] = e^{-\lambda \cdot (x+y)} \neq e^{-\lambda x} \cdot e^{-\lambda y}
	\end{split}
\end{equation}
\textbf{why?}
\begin{enumerate}
	\item Pick uniformly an index $i \to x_i $
	\item Pick uniformly a time $t \to X$ which contains t
\end{enumerate}

Then in 2 I get a bias because I tend to favor a longer interval over shorter ones, whereas in 1 I get F(x).

\section{Asymptotic results}
\begin{theorem}[Ross p. 101]
%{\textbf{Ross p. 101}}
Let $S_n = \sum \limits_{k=1}^{n}X_k$ a finite sum with $n<+\infty$ as there can't be infinite renewals in a finite time.
Then
\begin{equation}
	\begin{split}
		\frac{S_n}{n}\xrightarrow{n\rightarrow\infty}\mu &= \exp[X] \quad \text{with probability 1} \\
		&\text{\textsc{\textbf{Also:}}}\\
		N(\infty) = \lim_{t \to +\infty}N(t) &= \infty \quad \text{with probability 1}
	\end{split}
\end{equation}
\end{theorem}
In essence this results states that in finite time we have a finite number of renewals. Viceversa in infinite time we have infinite renewals.
\begin{proof}
If we have infinite time, what is the case where we have a finite number of renewals?
$\rightarrow$ when we have a last renewal $\rightarrow$ we have for some $n$ an infinite interarrival time
	\begin{equation}
		\begin{split}
			\prob[N(\infty)<\infty] &= \prob[X_n = \infty \text{ for some n}] = \prob[\bigcup\limits_{n=1}^{+\infty}\{X_n = \infty \}] \\
			&\le \sum\limits_{n=1}^{+\infty}\prob[X_n = \infty] = 0 \\
			&\text{because } F(\infty)=1
		\end{split}
	\end{equation}
\end{proof}

\begin{theorem}[Elementary renewal theorem]%Prop. 3.3.1 (Ross p. 102), KT pp 437
	\begin{equation}
		\lim_{t \to +\infty} \frac{N(t)}{t} = \frac{1}{\mu} \quad \text{with probability 1}
	\end{equation}
\end{theorem}

So as $t \to\infty$, $N(t)\to\infty$ \textbf{linearly} in $t$.
\begin{proof}
	\begin{equation}
		\begin{split}
			S_{N(t)} \le t < S_{N(t)+1} \quad \frac{S_{N(t)}}{N(t)} \le t &< \frac{S_{N(t)+1}}{N(t)}\\
			&=\frac{S_{N(t)+1}}{N(t)+1} \cdot \frac{N(t)+1}{N(t)}
		\end{split}
	\end{equation}
	We know that $N(t)\xrightarrow{t\to +\infty} \infty$ with probability 1
	$$\implies \lim_{t \to +\infty} \frac{S_{N(t)}}{N(t)} =\lim_{N \to +\infty} \frac{S_{N}}{N} = \mu \quad \text{w.p. 1 for LLN}$$

	So
\begin{equation}
	\mu \le \lim_{t \to +\infty} \frac{t}{N(t)} \stackrel{(1)}{\le}\mu \quad \implies \lim_{t \to +\infty} \frac{t}{N(t)} = \mu
\end{equation}
Where in $(1)$ the strict $<$ became $\le$ as we were dealing with limits.
\end{proof}

\textbf{(K.T. p. 102)}
%\begin{theorem}[K.T. page 102]
\begin{equation}
	\begin{split}
		M(t) &= \exp[N(t)] = \sum\limits_{j=1}^{+\infty}F_j(t) \\
		F_n(t) &= \int\limits_0^t F_{n-m}(t-\xi) dF_m(\xi) \quad 1 \le m \le n-1\\
		& \le \int\limits_0^t F_{n-m}(t) dF_m(\xi) \le F_{n-m} \cdot F_m(t) \quad \text{upper bound is valid if }\xi \to 0 \\
		&\implies \sum\limits_{j=1}^{+\infty}F_j(t)= \sum\limits_{n=0}^{+\infty} \sum\limits_{k=1}^{r}F_{n \cdot r + k}(t) \\
		F_{n \cdot r + k} (t) &\le F_r(t) \cdot F_{(n-1)\cdot r + k}(t) \le F_r^2(t) \cdot F_{(n-2)\cdot r +k}(t) \le \dots
		\le \left[F_r(t)\right]^n \cdot F_k(t)\\
		\sum\limits_{j=1}^{+\infty}F_j(t) &\le \sum\limits_{n=0}^{+\infty} \sum\limits_{k=1}^{r}\left[F_r(t)\right]^n \cdot F_k(t)
		= \sum\limits_{n=0}^{+\infty} \left[F_r(t)\right]^n \cdot \sum\limits_{k=1}^{r}F_k(t)
	\end{split}
\end{equation}
The sum converges unless $F_r(t)=1$ with geometric distribution.
\begin{equation}
	F_r(t)=\prob[S_r\le t]=\prob[\sum\limits_{i=1}^r X_i \le t]
\end{equation}
I can choose $r$ sufficiently large such that I can set $F_r(t)<1$ strictly. \\
So, formally
%\begin{equation*}
	$$\exists t_0 >0 \text{ s.t. } F(t_0)<1 \quad \forall t \mbox{ }	\exists r \text{ s.t. } F_r(t)<1$$
%\end{equation*}
\begin{equation*}
	\prob[S_r >t] = \prob\left[\sum\limits_{i=1}^r X_i > t \right] \ge
	\left(\prob\left[X_i > \frac{t}{r}\right]\right)^r = \left[1-F\left(\frac{t}{r}\right)\right]^r>0
	\quad \text{if }\frac{t}{r}<t_0
\end{equation*}
We can conclude
\begin{enumerate}
	\item $F_n(t)\xrightarrow{n\to +\infty}0$ at least geometrically
	\item $M(t)<\infty \quad \forall t < \infty, \text{ on the other hand }	M(t)\xrightarrow{t \to +\infty}+\infty$
\end{enumerate}

\textbf{We saw that:}
$$\exp[a(t-X)]=\int a(t-x)\cdot dF(x)$$

We now want to extend it to another monothonic function which is not a probability distribution function.

\begin{definition}[Convolution]
	For any monothonic function $A$ and for any well behaved function $B$ we define the convolution as
	\begin{equation}\begin{split}
		A \ast B &= \int\limits_0^t B(t-\eta)\cdot dA(\eta) = B \ast A \\
		\implies &\int a(t-x)\cdot dM(x) = M \ast a ~(t)
	\end{split}\end{equation}
\end{definition}

\section{Renewal argument}
We will firstly define it as conditioned to a particular value of $X_1$ and then we will extend it.

$X_1 = x \quad \implies M(t)= \exp[N(t)]$ \\
The starting point is
\begin{equation}
	\exp[N(t)| X_1=x] =
	\begin{cases}
	0 & x>t \quad \text{the renewal has yet to happen} \\
	1+M(t-x) & x \le t
	\end{cases}
\end{equation}
\begin{equation}
	\begin{split}
	M(t)= \exp[N(t)]&=\int\limits_0^{+\infty}\exp[N(t)|X_1=x] \cdot dF(x)\\
	&=\int\limits_0^{t}[1+M(t-x)] \cdot dF(x)\\
	&= F(t) + \int\limits_0^{t}M(t-x) \cdot dF(x)\\
	&= F(t) + F \ast M ~ (t)
	\end{split}
\end{equation}

\section{Renewal Equation}
\begin{equation}
		A(t) = a(t) +\int\limits_0^{t}A(t-x) \cdot dF(x) \quad \text{ in general}
\end{equation}
with $a(t)$ given and $F(x)$ the common distribution. If $a(t)=F(t) \implies$ we have the equation for $M(t)$.

\begin{theorem}[4.1 K.T. p.184]
	Let a(t) be a bounded function. The renewal equation has an unique solution with
	the property of being bounded on finite intervals and such solution is
	\begin{equation}
		A(t) = a(t) + \int\limits_0^{t}[a(t-x)] \cdot dM(x)
	\end{equation}
\end{theorem}
In other words it exists an unique solution that doesn't diverge in finite time.
\begin{proof}
	The proof is in three steps: boundness, existence and uniqueness.
	\proofpart
	\textsc{Boundness}\label{req:boundness}
	\begin{equation}\begin{split}
		|A(t)| & \le |a(t)| + \int\limits_0^{t}|a(t-x)| \cdot dM(x) \\
		\sup_{0\le t \le T} |A(t)| & \le \sup_{0\le t \le T} |a(t)| + \int\limits_0^{T}\sup_{0\le \eta \le T}|a(\eta)| \cdot dM(x) \\
		& = \sup_{0\le t \le T} |a(t)| \cdot (1+M(T)) < \infty \text{ as }
		\begin{cases}
			|a(t)| & \text{bounded for hypothesis} \\
			M(t) < \infty & \text{for } t<\infty
		\end{cases}
	\end{split}\end{equation}

	\proofpart
	\textsc{Existence}
		\begin{equation}\begin{split}
			A(t) &= a(t) + M \ast a~(t) = a(t) + \left(\sum\limits_{k=1}^{+\infty} F_k \right) \ast a~(t) \\
			&= a(t) + F \ast a~(t) +\left(\sum\limits_{k=2}^{+\infty} F_k \right) \ast a~(t)\\
			\text{\textbf{Reminder:}}&\text{ each $F_k , k>1$ is the convolution with itself k times $F_k = F \ast F_{k-1}$} \\
			\implies A(t) &= a(t) + F \ast \left[ a(t) + \left(\sum\limits_{k=1}^{+\infty} F_k \right) \ast a~(t) \right] \\
			&=a(t) + F \ast A ~ (t) \quad \text{ which is the renewal equation.}
		\end{split}\end{equation}
	\proofpart
	\textsc{Uniqueness}
	\begin{equation}\begin{split}
		A(t) &= a(t) + F \ast A(t) \quad \text{which is a recursive expression.} \\
		&= a(t) + F \ast \left[a~(t) + F \ast A~(t) \right] = a(t) + F \ast a ~ (t) + F_2 \ast A~(t) \\
		&= a(t) + F \ast a ~ (t) + F_2 \ast \left[a~(t) + F \ast A~(t) \right] \\
		&= a(t) + F \ast a~(t) + F_2 \ast a~(t) + F_3 \ast A~(t) = \dots \\
		&\text{after n steps we obtain} \\
		A(t) &= a(t) + \left( \sum\limits_{k=1}^{n-1}F_k\right) \ast a~(t) + F_n \ast A~(t) \\
		& \sum\limits_{k=1}^{n-1}F_k \xrightarrow{n \to +\infty} M \quad \implies A(t) = a(t) + M \ast a~(t) + \lim_{n \to +\infty} F_n \ast A~(t) \\
		&\text{For our proof we want to show that the limit goes to zero:} \\
		|F_n \ast A~(t)| &= |\int\limits_0^{t}A(t-\eta) \cdot dF_n(\eta)| \le \int\limits_0^{t}|A(t-\eta)| \cdot dF_n(\eta) \\
		& \le \sup\limits_{0 \le \eta \le t} |A(\eta)| \cdot F_n (t) < +\infty \quad \text{ for what we found in \ref{req:boundness}} \\
		&\implies |F_n \ast A~(t)| \xrightarrow{n \to +\infty} 0 \quad\text{ at least geometrically.}
	\end{split}\end{equation}
\end{proof}

\remark
Let's now focus on the expectation for a \gls{st} and let's proove that for a \gls{pp}:
\begin{equation}
	\exp[S_{N(t)+1}] = \exp\left[\sum\limits_{i=1}^{N(t)+1}X_i\right] = \exp[N(t)+1]\cdot \exp[X] \text{\textbf{but}} \exp[S_{N(t)}] \neq \exp[N(t)]\cdot \exp[X]
\end{equation}

\begin{proof}
	\begin{equation}\begin{split}
		A(t) &= \exp[S_{N(t)+1}]\\
		\exp[S_{N(t)+1}|X_1=x] &=
		\begin{cases}
			x & x>t \quad \text{no renewal has been seen} \\
			x + A(t-x) & x \le t \quad \text{\gls{pp} restarts at every renewal}
		\end{cases} \\
		A(t) &= \int\limits_0^{+\infty} \exp[S_{N(t)+1}|X_1 = x] \cdot dF(x) \\
		&= \int\limits_0^{t} [x+ A(t-x)] \cdot dF(x) + \int\limits_t^{+\infty} x \cdot dF(x) \\
		&= \underbrace{\int\limits_0^{+\infty} x \cdot dF(x)}_{\exp[X_1]} + \int\limits_0^{t} A(t-x) \cdot dF(x) \\
		&= \exp[X_1] + \int\limits_0^{t} A(t-x) \cdot dF(x)\\
		& \text{\textbf{If} }\exp[X_1] < \infty \implies A(t) \text{ is bounded} \\
		\implies A(t) &= \exp[X_1] + \int\limits_0^{t} \exp[X_1] \cdot dM(x) = \exp[X_1]\cdot [1+M(t)]\\
	\end{split}\end{equation}
\end{proof}

\section{Wald's equation}
\begin{definition}[Stopping Time]
A random variable N (integer valued), is called "stopping time" (ST) for the i.i.d. sequence $X_i$ if:
\begin{equation}
	\{N=n\} \text{ is independent of }X_i ,\quad i > n
\end{equation}
\end{definition}

\begin{theorem}[Wald's equation]
	Let $X_1, X_2, \dots, X_N $ be i.i.d, $\exp[X] < \infty$ and N a stopping time such that: $\exp[N] < \infty$. Then:

	\begin{equation}
		\exp\left[\sum\limits_{n=1}^N X_n \right] = \exp[N] \cdot \exp[X]
	\end{equation}
\end{theorem}
---
\begin{proof}
	We are gonna use a trick that will allow us to write the random sum as an infinite sum:\\ \\
	Let $I_n = \begin{cases} 1 & N \ge n \\ 0 & N<n \end{cases}$ \quad be our indicator function,\\
	This allows us to write: $\sum\limits_{n=1}^N X_n = \sum\limits_{n=1}^{+\infty} X_n \cdot I_n$
	\begin{equation}\begin{split} \label{wald:proof}
		\{I_n=1\} &= \{N \ge n \} \text{ event}\\
		&= \bigcup\limits_{i=1}^{n-1}\{\underbrace{N \neq i}_{\text{depend on } X_1, \dots, X_i} \} \\
		&\implies \{I_n=1\} \text{ is independent of }X_n, X_{n+1}, \dots\\
		\exp\left[\sum\limits_{n=1}^{N}X_n\right] &= \exp\left[\sum\limits_{n=1}^{N}X_n \cdot I_n \right] \stackrel{(1)}{=} \sum\limits_{n=1}^{+\infty}\exp[X_n \cdot I_n] \\
		&=\sum\limits_{n=1}^{+\infty}\exp[X_n] \cdot \exp[I_n] \stackrel{\text{X i.i.d.}}{=} \exp[X]\cdot\sum\limits_{n=1}^{+\infty}\exp[I_n] \\
		&= \exp[X] \cdot \sum\limits_{n=1}^{+\infty}\prob[N \ge n] = \exp[X] \cdot \exp[N]
	\end{split}\end{equation}
\end{proof}

\subsection{Discussion on Wald's equation proof}
	In the equation \ref{wald:proof} we should see if the passage marked with (1) is allowed.
	If we use $|X_n|>0$, the infinite sum is allowed and it's surely positive and finite, as the expectation of each X is finite.
	With $X_n$ the sum is bounded by $|X_n|$, which allows the switching for the Lebesgue theorem.

\subsection{Examples}
	\begin{enumerate}
		\item $\prob[X_i=0]=\prob[X_i = 1] = \frac{1}{2}$ and $N = \min\{n : X_1 + X_2 + \dots + X_N =10\}$ is a \gls{st}, and in particular
		$10 = \exp[N] \cdot \exp[X] = 0.5 \cdot \exp[N] \implies \exp[N]=20$
		\item $\prob[X_i=-1]=\prob[X_i = 1] = \frac{1}{2}$ and $N = \min\{n : X_1 + X_2 + \dots + X_N =1\}$ is a \gls{st}, but the expected stop time
		is $1 = \exp[N] \cdot \exp[X] = 0 \cdot \exp[N] \implies $ ABSURD. We conclude that Wald's equation doesn't apply. So it must be that N has not finite mean $\implies \exp[N]=\infty$
	\end{enumerate}

\section{The key renewal theorem}
\begin{definition}
	(Point of increase) Given a distribution function F we call \textit{point of increase} every point $\alpha$ such that:
	\begin{equation}
		F(\alpha+\epsilon)-F(\alpha-\epsilon)>0 \quad  \forall \quad
		\epsilon > 0
	\end{equation}
\end{definition}
\begin{definition}
	(Arithmetic function) We say that a dristibution function F is \textit{arithmetic} if $\exists$ $\lambda > 0$ such that F has points of increase exclusively among the points 0, $\pm \lambda$, $\pm 2\lambda$, ... . \\
	We call \textit{SPAN} the largest $\lambda$ for which F is still arithmetic.
\end{definition}

The distribution function of a discrete random variable with possible values 0,1,2,... is an arithmetic function with SPAN=1.

\begin{definition}
	(Directly Riemann Integrable Function) Given a function g defined on [0, $\infty$) we define the following quantities for every $\delta > 0$:
	\begin{align*}
		\underline \sigma (\delta) = \delta \cdot \sum_{n=1}^{\infty} min\{g(t):(n-1)\delta \leq t \leq n \delta \}
		\\
		\bar \sigma (\delta) = \delta \cdot \sum_{n=1}^{\infty}max\{g(t):(n-1)\delta \leq t \leq n \delta \}
	\end{align*}
	We say that g is directly Riemann integrable if both $\underline \sigma (\delta)$ and $\bar \sigma (\delta)$ converge absolutely $\forall \quad \delta > 0$ and if:
	\begin{equation}
		\underline \sigma (\delta) - \bar \sigma (\delta) \rightarrow 0 \quad \delta \rightarrow 0
		\end{equation}
\end{definition}

We note that every function for which $\int_{0}^{\infty} |g(t)| dt$ < $\infty$ (g is absolutely integrable) is directly Riemann integrable.

\begin{theorem}
	(Key Renewal Theorem) Is given a distribution function F of a positive random variable $a$ with mean $\mu$. We suppone that $a$ is directly Riemann integrable and that $A$ is the solution of the \textit{renewal equation}
	\begin{equation}
		A(t)=a(t)+\int_{0}^{t}A(t-x)dF(x)
	\end{equation}
	If F is not arithmetic, then:
	\begin{equation*}
		\lim_{t \rightarrow \infty} A(t) =
		\begin{cases}
			\frac{1}{\mu} \int_{0}^{\infty}a(x)dx \quad & if \quad \mu < \infty
			\\
			0 \quad & if \quad \mu = \infty
		\end{cases}
	\end{equation*}
	If F is arithmetic with SPAN = $\lambda$ then $\forall c > 0$:
	\begin{equation*}
		\lim_{t \rightarrow \infty} A(c+n\cdot \lambda) =
		\begin{cases}
			\frac{\lambda}{\mu} \sum_{n=0}^{\infty}a(c+n \cdot \lambda) \quad & if 	\quad \mu<\infty
			\\
			0 \quad & if \quad \mu = \infty
		\end{cases}
	\end{equation*}
\label{KRT1}
\end{theorem}

The theorem \ref{KRT1} can be also expressed in the following form:

\begin{theorem}
	(Key renewal theorem) Is given a distribution function F of a positive random variable with mean $\mu$. We suppone $h>0$ and that $M(t)=\sum_{k=1}^\infty F_{k}(t)$ is the \textit{renewal function} associated with F.
	If F is not arithmetic then:
	\begin{equation}
		\lim_{t \rightarrow \infty} [M(t+h)-M(t)]=\frac{h}{\mu}
	\end{equation}
	If F is arithmetic with SPAN = $\lambda$ then:
	\begin{equation}
		\lim_{t \rightarrow \infty} [M(t+h)-M(t)]=\frac{h}{\mu} \quad \forall h = n \cdot \lambda
	\end{equation}
	\label{KRT2}
\end{theorem}

We note that the \textit{elementary renewal theorem} $\lim_{t \to \infty} \frac{1}{t} M(t) = \frac{1}{\mu}$ is a corollary of the \textit{key renewal theorem} \ref{KRT2}.

\subsection{Application of the key renewal theorem}

\paragraph{Limiting distribution of the excess life}

We say that $\gamma_{t}=S_{N(t)+1}-t$ is the excess life at time t and that $A_z=Prob[\gamma_t>z]$ for a fixed $z>0$. We obtain that:
\begin{equation*}
	Prob[\gamma_t>z|X_1=x] = \begin{cases}
		1 \quad & if \quad x > t+z \\
		0 \quad & if \quad t+x \geq x > t \\
		A_z(t-x) \quad & if \quad t \geq x > 0
	\end{cases}
\end{equation*}
For the law of the total probability we obtain that:
\begin{align*}
	A_z(t)= & \int_{0}^{\infty} Prob[\gamma_t>z|X_1=x] dF(x) = \int_{0}^{t}A_z(t-x)dF(x)+\int_{t+z}^{\infty}dF(x)= \\ & \int_{0}^{t}A_z(t-x)dF(x)+1-F(t+z)
\end{align*}
For the \textit{renewal equation} $ A(t)=a(t)+\int_{0}^{t}A(t-x)dF(x)=a(t)+\int_{0}^{t}a(t-x)dM(x) $ we conclude that:
\begin{align*}
	& a(t) = 1 - F(t+z) \\
	& A_z(t)=\int_{0}^{t}(1-F(t+z-x))dM(x)+1-F(t+z) \\
	& \int_{0}^{\infty} a(x) d(x) = \int_{0}^{\infty}(1-F(x)) d(x) = \int_{z}^{\infty}(1-F(y))dy \leq \int_{0}^{\infty}(1-F(y))dy = \mu
\end{align*}
We suppone $\mu < \infty$. For the \textit{renewal theorem} we obtain that:
\begin{equation}
	\lim_{t \rightarrow \infty} Prob[\gamma_t>z] = \lim_{t \rightarrow \infty} A_z(t) = \frac{1}{\mu} \cdot \int_z^{\infty}(1-F(x))dx \quad \forall z > 0
	\label{limitingdistribution}
\end{equation}

From \ref{limitingdistribution} we can determine the limiting distribution for the \textit{current life} $\delta_t$ and for the \textit{total life} $\beta_t$. First we note that:
\begin{equation}
	\{\gamma_t \geq x, \delta_t \geq y \} \Leftrightarrow \{\gamma_{t-y} \geq x+y \}
	\label{currtotallife}
\end{equation}
From \ref{currtotallife} we have that:
\begin{align*}
	\lim_{t \rightarrow \infty} Prob[\delta_t \geq y, \gamma_t \geq x] & = \lim_{t \rightarrow \infty} Prob[\gamma_{t-y} \geq x+y] \\ & = \frac{1}{\mu} \cdot \int_z^{\infty}(1-F(z))dz
\end{align*}
In particular we have that:
\begin{align*}
	\lim_{t \rightarrow \infty} Prob[\delta_t \geq y] & = \lim_{t \rightarrow \infty} Prob[\delta_t \geq y, \gamma_{t} \geq 0] \\ & = \frac{1}{\mu} \cdot \int_z^{\infty}(1-F(z))dz
\end{align*}
$\frac{1-F(z)}{\mu}$ is the probability density function of $\delta_t$. We are able to compute $\delta_t$ and $\gamma_t$ averages.
\begin{align*}
	\exp[\delta_t]=\exp[\gamma_t] & =\int_z^{\infty} \frac{z}{\mu} \cdot (1-F(z))dz \\ & = \frac{z^2}{2\mu}(1-F(z))|_0^{\infty}+\int_0^{\infty}\frac{z^2}{2 \mu} f(z)dz= \frac{\exp[X^2]}{2 \exp[X]}
\end{align*}
Finally we conclude that:
\begin{align}
	& \exp[\delta_t] = \frac{\exp[X^2]}{2 \exp[X]}
	\\ & \exp[\gamma_t] = \frac{\exp[X^2]}{2 \exp[X]}
	\\ & \exp[\beta_t] = \frac{\exp[X^2]}{\exp[X]}
\end{align}

\paragraph{Asymptotic expansion of the renewal function}

Given a distribution function of mean $\mu$ and variance $\sigma$ we want to prove that $\lim_{t \rightarrow \infty} (M(t) - \frac{t}{\mu}) = \frac{\sigma^2-\mu^2}{2\mu^2}$. For $t \rightarrow \infty$ we have what follows:
\begin{align*}
	M(t)-\frac{t}{\mu} & =\exp[N(t)+1]-\frac{t}{\mu}-1 \\
	& = \frac{1}{\mu} \cdot (\exp[S_{N(t)+1}]-t)-1 \\
	& = \frac{1}{\mu} \cdot \exp[\delta_t]-1 \\
	& = \frac{1}{\mu}\frac{\exp[X^2]}{2\mu}-1 \\
	& = \frac{\sigma^2+\mu^2}{2\mu^2}-1 \\
	& = \frac{\sigma^2-\mu^2}{2\mu^2}
\end{align*}
Then we conclude that:
\begin{equation}
	\lim_{t \rightarrow \infty} (M(t) - \frac{t}{\mu}) = \frac{\sigma^2-\mu^2}{2\mu^2}
\end{equation}

\subsection{Delayed renewal processes}

We assume that $\{X_k\}$ are independent positive random variables but only $X_2,X_3,...$ are identically distribuited. $X_1$ has a distribution function G that differs from the distribution function F of the other variables. We call such process \textit{delayed renewal process}. Given an ordinary renewal process we can obtain a \textit{delayed renewal process} if we fix the time origin $t=0$ a certain time after the start of the ordinary process. We put $S_0=0$ and $S_n=X_1+X_2+...+X_n$ and $N(t)$ equal to the number of renewal at time t. We must distinguish between the mean number of renewals in the delayed process $M_D(t)$ and the renewal function associated with F $M(t)$.
\begin{align}
	& M_D(t) = \exp[N(t)]
	\\ & M(t) = \sum_{k=1}^{\infty}F_k(t)
\end{align}
Now we want to prove what follows:
\begin{align*}
	& \lim_{t \to \infty }\frac{M_D(t)}{t}=\frac{1}{\mu}
	\\ & \lim_{t \to \infty }[M_D(t)-M_D(t-d)]=\frac{d}{\mu}
\end{align*}

We have already seen that for a recurrent irreducible aperiodic Markov Chain the following statament is true.
\begin{equation}
	\lim_{n \to \infty} P_{jj}^{(n)}=\pi_j=\frac{1}{m_j}=\frac{1}{\sum_{n=1}^{\infty}n \cdot f_{jj}^{(n)}}
\end{equation}
Given a reccurent state $j$ we call $N_j(t)$ the number of visits in j by the time t. The following statament is always true for any initial state $Y_0$.
\begin{equation}
	N_j(n)-N_j(n-1)=1 \quad \Leftrightarrow \quad Y_n=j
\end{equation}
If $Y_0$ is equal to j, then $N_j$ is a ordinary renewal process. We keep $Y_0=j$ and we obtain what follows.
\begin{align*}
	& \exp[N_j(n)-N_j(n-1)|Y_0=j]=M(n)-M(n-1)=P_{jj}^{(n)}
	\\ & \Rightarrow \pi_j=\frac{1}{m_j}=\lim_{n \to \infty} P_{jj}^{n} = \lim_{n \to \infty} [M(n)-M(n-1)]=\frac{1}{\mu}
\end{align*}
So we have proved that:
\begin{equation}
	\lim_{n \to \infty} P_{jj}^{n}=\frac{1}{\mu}
\end{equation}
If $Y_0=i \neq j$, then $N_j(n)$ is a delayed renewal process. We keep $Y_0=i \neq j$ and we obtain what follows.
\begin{align*}
	& \exp[N_j(n)-N_j(n-1)|Y_0=i \neq j]=M_D(n)-M_D(n-1)=P_{jj}^{(n)}
	\\ & \Rightarrow \frac{1}{\mu}=\lim_{n \to \infty} P_{jj}^{n} = \lim_{n \to \infty} [M_D(n)-M_D(n-1)]
\end{align*}
So we have proved that:
\begin{equation}
	\lim_{n \to \infty} [M_D(n)-M_D(n-1)]=\frac{1}{\mu} \Rightarrow \lim_{t \to \infty }\frac{M_D(t)}{t}=\frac{1}{\mu}
\end{equation}
Now we consider a periodic Markov Chain with period $d$. We define $N_j$ as before. The following statament is always true for any initial state $Y_0$.
\begin{equation}
	N_j(n \cdot d)-N_j((n-1)\cdot d)=1 \quad \Leftrightarrow \quad Y_{n \cdot d}=j
\end{equation}
For $Y_0=j$ we obtain what follows.
\begin{align*}
	& \exp[N_j(n \cdot d)-N_j((n-1)\cdot d)|Y_0=j]=M(n \cdot d)-M((n-1)\cdot d)=P_{jj}^{(n \cdot d)}
	\\ & \Rightarrow d \cdot \pi_j=\frac{d}{m_j}=\lim_{n \to \infty} P_{jj}^{n \cdot d} = \lim_{n \to \infty} [ M(n \cdot d)- M( (n-1) \cdot d)]=\frac{d}{\mu}
\end{align*}
So we have proved that:
\begin{equation}
	\lim_{n \to \infty} P_{jj}^{n \cdot d}=\frac{d}{\mu}
\end{equation}
For $Y_0 \neq j$ we obtain what follows.
\begin{align*}
	& \exp[N_j(n \cdot d)-N_j((n-1) \cdot d)|Y_0=i \neq j]=M_D(n \cdot d)-M_D((n-1) \cdot d)=P_{jj}^{(n \cdot d)}
	\\ & \Rightarrow \frac{d}{\mu}=\lim_{n \to \infty} P_{jj}^{n \cdot d} = \lim_{n \to \infty} [M_D(n \cdot d)-M_D((n-1) \cdot d)]
\end{align*}
So we have proved that:
\begin{equation}
	\lim_{n \to \infty} [M_D(n \cdot d)-M_D((n-1) \cdot d)]=\frac{d}{\mu} \Rightarrow \lim_{t \to \infty }[M_D(t)-M_D(t-d)]=\frac{d}{\mu}
\end{equation}

\subsection{Cumulative and related renewal process}
We associate to every random varriable $X_i$ a second random variable $Y_i$. So $Y_i$ and $X_i$ are dependent but $(X_i,Y_i)$ and $(X_j,Y_j)$ are independent. We call F the distribution function of $X_i$, G the distribution function of $Y_i$, $\mu$ the mean of $X_i$ and $\nu$ the mean of $Y_i$.
\paragraph{Queieng model}
Suppose to ahve queieng system in which the arrivals follow a Poisson process. $X_i$ represents the the period between two consequent arrivals. $Y_i$ is a portion $X_i$ and represents the period in which the queieng system is busy. We call $p(t)$ the probability that t falls into some portion $Y_i$. We suppone that the first interval has length $X_1=x$ and we obtain what follows.
\begin{align*}
	p(t) & =Prob[t \in Y |X_1 = x]=\begin{cases}
		Prob[Y_1>t|X_1=x] \quad & if \quad x \geq t
		\\ p(t-x) \quad & if \quad x<t
	\end{cases}
	\\ & = \int_0^t p(t-x)dF(x)+\int_t^{\infty}Prob[Y_1>t|X_1=x]dF(x)
\end{align*}
Knowing that $\int_0^{t}Prob[Y_1>t|X_1=x]dF(x)=0$ we have that:
\begin{align*}
	p(t) & = \int_0^t p(t-x)dF(x)+\int_0^{\infty}Prob[Y_1>t|X_1=x]dF(x)
	\\ & = Prob[Y_1>t]+\int_0^t p(t-x)dF(x)
\end{align*}
We know that $p(t)= Prob[Y_1>t]+\int_0^t p(t-x)dF(x)$ is a renewal equation. We can establish that $\int_0^{\infty}Prob[Y_1>t]dt=\exp[Y_1]=\nu$. Applying the renewal theorem we obtain what follows.
\begin{align*}
	\lim_{t \to \infty} p(t) & = \frac{1}{\mu}\cdot\int_0^{\infty}p(t)dt = \frac{\nu}{\mu}= \frac{\exp[X]}{\exp[Y]}
\end{align*}

\section{Reward Processes}

Consider a \textit{renewal process} $N(t)$ with interarrival time $X_n$ with distribution function $F$. We suppone that each time a renewal occurs we receive a \textit{reward}; we call $R_n$ the reward associated with the nth renewal event. We suppone that each reward $R_n$ depend on the length of the interval $X_n$. In this scenario the pairs $(X_n, R_n)$ are independent and identically distribuited. We define the total number of reward at time $t$ $R(t)$ as follows.
\begin{equation}
	R(t)=\sum_{n=1}^{N(t)}R_n
\end{equation}
Now we adopt the following definitions.
\begin{align*}
	\exp[X] & =\exp[X_n]
	\\ \exp[R] & =\exp[R_n]
\end{align*}
\begin{theorem}
  If $\exp[X]<\infty$ and $\exp[R]<\infty$ then with probability equal to 1 we have:
	\begin{equation}
		\lim_{t \to \infty}\frac{R(t)}{t}=\frac{\exp[R]}{\exp[X]}
		\label{rewardtheorem1}
	\end{equation}
	\begin{equation}
		\lim_{t \to \infty}\frac{\exp[R(t)]}{t}=\frac{\exp[R]}{\exp[X]}
		\label{rewardtheorem2}
	\end{equation}
\end{theorem}
\begin{proof}
	We want to prove \ref{rewardtheorem1}.
	\begin{align*}
		\frac{R(t)}{t}=\frac{\sum_{n=1}^{N(t)}R_n}{t}= \bigg( \frac{\sum_{n=1}^{N(t)}R_n}{N(t)}\bigg)\cdot\bigg(\frac{N(t)}{t}\bigg)
	\end{align*}
	By the strong law of large numbers we obtain that:
	\begin{align*}
		\lim_{t \to \infty}\frac{\sum_{n=1}^{N(t)}R_n}{N(t)}=\exp[R]
	\end{align*}
	By the renewal theorem we obtain that:
	\begin{align*}
		\lim_{t \to \infty}=\frac{1}{\exp[X]}
	\end{align*}
	Then \ref{rewardtheorem1} is proven.
\end{proof}
\begin{proof}
	We want prove \ref{rewardtheorem2}. We note immediately that $N(t)+1$ is a stopping time both for $X_1,X_2,X_3,...$ and for $R_1,R_2,R_3,..$.
	\begin{align*}
		\sum_{n=1}^{N(t)}R_n \leq R(t) \leq \sum_{n=1}^{N(t)+1}R_n
	\end{align*}
	Then we have that:
	\begin{align*}
		& \exp\bigg[\sum_{n=1}^{N(t)}R_n\bigg] \leq \exp[R(t)] \leq \exp\bigg[\sum_{n=1}^{N(t)+1}R_n\bigg]
		\\ & (M(t)+1)\exp[R]-\exp[R_{N(t)+1}] \leq \exp[R(t)] \leq (M(t)+1)\exp[R]
	\end{align*}
	Then, knowing that $\lim_{t \to \infty} \frac{(M(t)+1)\exp[R]}{t} = \frac {\exp[R]}{\exp[X]} $ we have that:
	\begin{align*}
		\frac {\exp[R]}{\exp[X]} - \lim_{t \to \infty} \frac{\exp[R_{N(t)+1}]}{t} \leq \lim_{t \to \infty} \frac{\exp[R(t)]}{t} \leq \frac{\exp[R]}{\exp[X]}
	\end{align*}
	We put $A(t)=\exp[R_{N(t)+1}]$ and we have that:
	\begin{align*}
		& \exp[R_{N(t)+1}|X_1=x]=
			\begin{cases}
				\exp[R_1|X_1=x] \quad & if \quad x>t
				\\ A(t-x) \quad & if \quad x \leq t
			\end{cases}
		\\ & \Rightarrow
		\\ & A(t)=\int_{0}^{t}A(t-x)dF(x)+\int_{t}^{+\infty}\exp[R_1|X_1=x]dF(x)
	\end{align*}
	We put $a(t)=\int_{t}^{+\infty}\exp[R_1|X_1=x]dF(x)$ and we have that:
	\begin{align*}
		A(t)=\int_{0}^{t}a(t-x)dM(x)+a(t)=(M \ast a) (t)+a(t)
	\end{align*}
	Assuming that $R_n \geq 0$ we have that:
	\begin{align*}
		& \lim_{t \to \infty}a(t) = \lim_{t \to \infty}\int_{t}^{+\infty}\exp[R_1|X_1=x]dF(x)=0
		\\ & a(0)=\int_{0}^{+\infty}\exp[R_1|X_1=x]dF(x)=\exp[R_1]<+\infty
	\end{align*}
	\begin{align*}
		|a(t)| & \leq \int_{t}^{+\infty}\exp[|R_1||X_1=x]dF(x)
		\\ & \leq \int_{0}^{+\infty}\exp[|R_1||X_1=x]dF(x) = \exp[|R_1|]=\exp[R_1]<+\infty
	\end{align*}
	So we have come to the following results:
	\begin{align*}
		1) \quad & \forall \epsilon>0 \quad \exists T>0:\quad |a(t)|<\epsilon \quad \forall t>T
		\\ 2) \quad & |a(t)| \leq \exp[|R_1|]<+\infty \quad \forall t
	\end{align*}
	Knowing that $A(t)=\int_{0}^{t}a(t-x)dM(x)+a(t)$ we have that:
	\begin{align*}
		|A(t)| & = |\int_{0}^{t}a(t-x)dM(x)+a(t)| \leq \int_{0}^{t}|a(t-x)|dM(x)+|a(t)|
		\\ & \leq \int_{0}^{t-T}|a(t-x)|dM(x)+ \int_{t-T}^{t}|a(t-x)|dM(x) + a(t)
		\\ & \leq \int_{0}^{t-T}\epsilon dM(x)+ \int_{t-T}^{t}\exp[|R_1|] dM(x) + a(t)
	\end{align*}
	\begin{align*}
		\lim_{t \to \infty} \frac{A(t)}{t} \leq \lim_{t \to \infty} \epsilon \cdot \frac{M(t-T)}{t} + \lim_{t \to \infty} \exp[|R_1|]\cdot \frac{M(t)-M(t-T)}{t} + \lim_{t \to \infty} \frac{a(t)}{t}
	\end{align*}
	Knowing that $\lim_{t \to \infty} \epsilon \cdot \frac{M(t-T)}{t}=\frac{\epsilon}{\exp[X]}$, $\lim_{t \to \infty} \exp[|R_1|]\cdot \frac{M(t)-M(t-T)}{t}=0$ and $\lim_{t \to \infty} \frac{a(t)}{t}=0$ we have that:
	\begin{align*}
		\lim_{t \to \infty} \frac{A(t)}{t} \leq \frac{\epsilon}{\exp[X]} \Rightarrow \lim_{t \to \infty} \frac{\exp[R_{N(t)+1}]}{t}=0 \Rightarrow \frac {\exp[R]}{\exp[X]} \leq \lim_{t \to \infty} \frac{\exp[R(t)]}{t} \leq \frac{\exp[R]}{\exp[X]}
	\end{align*}
	The we have that:
	\begin{align*}
		\lim_{t \to \infty} \frac{\exp[R(t)]}{t} = \frac{\exp[R]}{\exp[X]}
	\end{align*}
	Then \ref{rewardtheorem2} is proven.
\end{proof}

\section{Regenerative Processes}

Consider a stochastic process $\{X(t), t \geq 0\}$ with state space$\{0, 1, 2, ... \}$ having
the property that there exist time points at which the process (probabilistically) restarts itself. That is, suppose that with probability 1, there exists a time $S_1$
such that the continuation of the process beyond $S_1$ is a probabilistic replica
of the whole process starting at 0. Note that this property implies the existence
of further times $S_2 , S_3 , \dots$ having the same property as $S_1$. Such a stochastic
process is known as a \emph{regenerative process}.
From the above, it follows that $\{S_1 , S_2 , ...\}$ constitute the event times of
a renewal process. We say that a cycle is completed every time a renewal
occurs. Let $N(t) = \max\{n: S_n \leq t\}$ denote the number of cycles by time t.

\section{Semi-Markov Processes}
A semi-Markov process is one that changes states in accordance with a Markov
chain but takes a random amount of time between changes. More specifically
consider a stochastic process with states $0, 1, ...  $, which is such that, whenever
it enters state $i, i\geq 0$:
\begin{enumerate}
	\item The next state is $j$ with probability $P_{ij}$
	\item Given that the next state is $j$, the time the transition takes is random with distribution $F_{ij}$ and independent of past and future
\end{enumerate}
If we let $Z(t)$ denote the state at time $t$, then $\{Z(t), t\leq 0\}$ is called a \emph{semi-Markov
process}.
Thus a semi-Markov process does not possess the Markovian property that
given the present state the future is independent of the past. For in predicting
the future not only would we want to know the present state, but also the
length of time that has been spent in that state\footnote{note that ``$Z(t) = \mbox{ state of the process at time } t$" is Markov only in the case where the distribution pdf od the transition time is memoryless (for example exponential), more in general $Z(t)$ is not Markovian.}. Of course, at the moment of transition, all we would need to know is the new state ( and nothing about
the past). %A Markov chain is a semi-Markov process in which

Let $H_i(t)$ denote the \emph{distribution of time} that the semi-Markov process spends
in state i before making a transition. That is, by conditioning on the next
state, we see
	\begin{equation}
		H_i(t) = \sum_j P_{ij} F_{ij}(t)
	\end{equation}

and let $\mu_i$ denote its mean. That is:
	\begin{equation}
		 \mu_i = \exp[H_i(t)] = \int_{0}^{+\infty}x \,dH_i(x)
	\end{equation}

\begin{definition}[Average return time]
	$\mu_{ii} = $ average time between two consecutive transition in state $i$
\end{definition}

\subsection{Regenerative Processes}

Consider a stochastic process $\{X(t), t \geq 0\}$ with state space$\{0, 1, 2, ... \}$ having
the property that there exist time points at which the process (probabilistically) restarts itself. That is, suppose that with probability 1, there exists a time $S_1$
such that the continuation of the process beyond $S_1$ is a probabilistic replica
of the whole process starting at 0. Note that this property implies the existence
of further times $S_2 , S_3 , \dots$ having the same property as $S_1$. Such a stochastic
process is known as a \emph{regenerative process}.
From the above, it follows that $\{S_1 , S_2 , ...\}$ constitute the event times of
a renewal process. We say that a cycle is completed every time a renewal
occurs. Let $N(t) = \max\{n: S_n \leq t\}$ denote the number of cycles by time t.

\subsection{Semi-Markov Processes}
A semi-Markov process is one that changes states in accordance with a Markov
chain but takes a random amount of time between changes. More specifically
consider a stochastic process with states $0, 1, ...  $, which is such that, whenever
it enters state $i, i\geq 0$:
\begin{enumerate}
	\item The next state is $j$ with probability $P_{ij}$
	\item Given that the next state is $j$, the time the transition takes is random with distribution $F_{ij}$ and independent of past and future
\end{enumerate}
If we let $Z(t)$ denote the state at time $t$, then $\{Z(t), t\leq 0\}$ is called a \emph{semi-Markov
	process}.
Thus a semi-Markov process does not possess the Markovian property that
given the present state the future is independent of the past. For in predicting
the future not only would we want to know the present state, but also the
length of time that has been spent in that state\footnote{note that ``$Z(t) = \mbox{ state of the process at time } t$" is Markov only in the case where the distribution pdf od the transition time is memoryless (for example exponential), more in general $Z(t)$ is not Markovian.}. Of course, at the moment of transition, all we would need to know is the new state ( and nothing about
the past). %A Markov chain is a semi-Markov process in which

Let $H_i(t)$ denote the \emph{distribution of time} that the semi-Markov process spends
in state i before making a transition. That is, by conditioning on the next
state, we see
\begin{equation}
H_i(t) = \sum_j P_{ij} F_{ij}(t)
\end{equation}

and let $\mu_i$ denote its mean. That is:
\begin{equation}
\mu_i = \exp[H_i(t)] = \int_{0}^{+\infty}x \,dH_i(x)
\end{equation}

Let $T_{ii}$ denote the time between successive transitions into state i and let
\begin{equation}
\mu_{ii}=\exp [T_{ii}]
\end{equation}
By using the theory of alternating renewal processes, it is a
simple matter to derive an expression for the limiting probabilities of a semi-Markov
process.

\begin{theorem}
	If the semi-Markov process is irreducible and if $T_{ii}$ has a non-lattice\footnote{boh} distribution with finite mean, then

	$$P_j = \lim_{t \to \infty} \prob[Z(t)=j | Z(0)=k]$$

	Exists and independent of the initial state. Furthermore,

	$$P_j = \frac{\exp[\mbox{time in state i in a cycle}]}{\exp[\mbox{duration of the cycle}]} = \frac{\mu_i}{\mu_{ii}}$$

\end{theorem}
Note that while $\mu_i$ is easy to compute, $\mu_{ii}$ is much more difficult.

\subsection{Renewal-Reward processes}

Let:

\begin{equation}
r_{ij} = \mbox{reward of transition } i\rightarrow j. \qquad R_{ij} = \exp[r_i]
\end{equation}
\begin{equation}
R_i = \sum_k P_{ik} R_{ik} = \mbox{ average reward of a visit to state } i
\end{equation}
$\theta_{ij} = $ total reward of going from i to j for the first time following any path
\begin{equation}
\theta_{ij} = \begin{cases}
&r_{ij} \quad\mbox{with probability } P_{ij}\\
&r_{ik}+\theta_{kj}  \quad\mbox{with probability } P_{ik}, k\neq j
\end{cases}
\end{equation}
\begin{equation*}
\rho_{ij} = \exp[\theta_{ij}] = \sum_{k=0}^{\infty}\exp[\theta_{ij}| X_1=k] P_{ik} = R_{ij}P_{ij} +\sum_{k \neq j} P_{ik} [R_{ik}+\rho_{kj}] = R_i + \sum_{k \neq j}P_{ik}\rho_{kj}
\end{equation*}

\begin{equation}
\Rightarrow\rho_{ij} = \exp[\theta_{ij}] =  R_i + \sum_{k \neq j}P_{ik}\rho_{kj}
\end{equation}


We have that:
\begin{equation*}
\sum_i \pi_i \rho_{ij} = \sum_i \pi_i R_i + \sum_i \sum_{k \neq j} \pi_i P_{ik} \rho_{kj} = \sum_j \pi_i R_i + \sum_{k \neq j}\rho_{kj}\sum_i\pi_i P_{ik}
\end{equation*}
So we have that for \emph{any} metric $r(\cdot)$
\begin{equation}
\Rightarrow\sum_i \pi_i \rho_{ij} = \sum_j \pi_i R_i + \sum_{k \neq j}\pi_k\rho_{kj},\qquad \pi_j\rho_{jj} = \sum_i \pi_i R_i
\end{equation}
if the metric is \emph{time}
\begin{equation}
\pi_j \mu_{jj} = \sum_i \pi_i \mu_i
\end{equation}

Now, in system modeling one of the main task of performance evaluation is to find te average value of some reward over time, that is to evaluate $\lim_{t \to \infty}\frac{R(t)}{t}$. The following result applies:
\begin{equation}
\lim_{t \to \infty}\frac{R(t)}{t} = \frac{\exp[R]}{\exp[X]} = \frac{\rho_{jj}}{\mu_{jj}} = \frac{\sum_i \pi_i \frac{R_i}{\pi_j}}{\sum_i \pi_i \frac{\mu_i}{\pi_j}} = \frac{\sum_i \pi_i \sum_j P_{ik} R_{ik}}{\sum_i \pi_i \sum_k P_{ik}T_{ik}}
\end{equation}

This is a powerful way to evaluate systems performances, in order for this model to apply 2 conditions need to be met:
\begin{enumerate}
	\item The system must be able to be modeled with a concept of \emph{state}.\footnote{That's good for us, every protocol is essentially a state machine}
	\item The process have to be Markovian or at least semi-Markovian
\end{enumerate}
