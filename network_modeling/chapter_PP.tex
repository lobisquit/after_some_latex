\chapter{Poisson Processes}
A Poisson process of intensity, or rate, $\lambda > 0$ is an integer-valued stochastic process ${X_t,	t \ge 0}$ for which:
\begin{enumerate}
	\item $X_0 = 0$
	\item For any time points $t_0 = 0 < t_1 < t_2 < \cdots < t_n$, the process increments
	$$X_{t_1}-X_{t_0}, X_{t_2}-X_{t_1}, \cdots, X_{t_n}-X_{t_{n-1}}$$
	are independent random variables, i.e. knowing the number of new arrivals doesn't help to know the next arrivals
	\item For $s \ge 0$ and $t > 0$, the random variable $X_{t+s} - X_s$ has the Poisson distribution
	\begin{equation}\label{p_dfist}
		\prob[X_{t+s} - X_s = n] = \frac{(\lambda t)^ne^{-\lambda t}}{n!}
	\end{equation}
	where
	\begin{equation}\label{p_dist_conseq}
		\begin{split}
			\prob[X_n \ge 1] &= \lambda n + o(n) \\
			\prob[X_n \ge 2] &= o(n)
		\end{split}
	\end{equation}
	\gls{kt} at page 226 shows that assuming \eq{p_dist} you can get \eq{p_dist_conseq} and viceversa.
\end{enumerate}

Interarrival times in a \gls{pp} are iid exponentials with parameter $\lambda$

\begin{tikzpicture}
	\begin{axis}[
		y = 1.5cm,
		hide y axis,
		axis x line = bottom,
		xtick={0,1,2,3,4},
		xticklabels={,,$s_0$,$s_1$,$s_2$,$\cdots$}
	]
	\end{axis}
\end{tikzpicture}


\begin{equation}
	\prob[S_0 > t] = \prob[\text{No arrivals in } [0,t]] = \frac{(\lambda t)^0 e^{-\lambda t}}{0!} = e^{-\lambda t}
\end{equation}
\begin{equation}\label{poiss_independence}
	\prob[S_1 > t | S_0 = s] = \prob[\text{No arrivals in } [s, s+t]] = \prob[S_1 > t] = e^{-\lambda t}
\end{equation}

Where \eq{poiss_independence} is possible because $S_0$ and $S_1$ are disjoint and so the condition on $S_0$ is independent on the $S_1$ slot.
In general,
\begin{equation}
	\prob[S_n > t | S_i = s_i, ~i=0,\cdots,n-1] = e^{-\lambda t}
\end{equation}

%LAW OF RARE EVENTS: rare events can be aproximated with a Poisson process? (non ho ben capito)
%REPLY: si dimostra che chiedere eventi rari Ã¨ equivalente a chiederly Poisson
\section{Properties}
	\begin{itemize}
		\item Consider the sum of two independent Poisson process with parameters $\lambda_1$ and $\lambda_2$, what is the outgoing process?
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}
				 \draw (0,0) circle [radius = 0.5];
				 \draw [->] (-2,1.2) -- (-0.5,0.5);
				 \draw [->] (-2,-1.2) -- (-0.5,-0.5);
				 \draw [->] (0.6, 0) -- (2.6,0);
				 \node at (-1.25, 1.3) {$\lambda_1$};
				 \node at (-1.25, - 1.3) {$\lambda_2$};
				 \node at (1.6 , 0.3) {$\lambda$};
			\end{tikzpicture}
		\end{figure}
		Given X $\sim \pois(\mu)$, Y $\sim \pois(\nu)$
		\begin{equation}
			\begin{split}
				 \prob[X + Y = n] &=	\sum\limits_{k=0}^n \prob[X = k, Y = n - k] \\
				 &=	\sum\limits_{k=0}^n \prob[X = k] \prob[Y = n - k] \\
				 &=	\sum\limits_{k=0}^n \frac{e^{-\mu} \mu^k}{k!} \frac{e^{-\nu}\nu^{n-k}}{(n-k)!}\\
				 &=	\frac{e^{-\mu + \nu}}{n!}\sum\limits_{k=0}^n \frac{n!}{k!(n-k)!}\mu^k\nu^{n-k}\\
				 &=	\frac{e^{-\mu + \nu}}{n!}(\mu + \nu)^n
			 \end{split}
		\end{equation}
		That is Poisson distributed with parameter $\mu + \nu$ (the sum of the two parameters). \\
		Therefore the outgoing process is posson distributed with parameter $\lambda = \lambda_1 + \lambda_2$.

		\item Now considering the opposite case: two processes generated by the splitting of one (into process $X_1(t)$ with probability $\rho$ and into process $X_2(t)$ with probability $1-\rho$)
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}
				\draw (0,0) circle [radius = 0.5];
				\draw [->] (0.5, 0.5) -- (2 , 1.2);
				\draw [->] (0.5,-0.5) -- (2, -1.2);
				\draw [->] (-2.6, 0) -- (-0.6, 0);
				\node at (1.25, 1.3) {$\lambda_1$};
				\node at (1.25, - 1.3) {$\lambda_2$};
				\node at (-1.6 , 0.3) {$\lambda$};
				\node at (2.5, 1.2) {$X_1(t)$};
				\node at (2.5, -1.2) {$X_2(t)$};
				\node at (-3.1, 0) {$X(t)$};
			\end{tikzpicture}
		\end{figure}
		The resulting processes are independent with parameters $\lambda_1=\lambda \rho$ and $\lambda_2 = \lambda (1 - \rho)$.
		\begin{proof}
			We already know that $\lambda_1 = \lambda \rho$ and $\lambda_2 = \lambda (1 - \rho)$, for construction of the splitter. We need to prove that the two processes are Poisson distributed and independent.
			\begin{equation}
				\begin{split}
					\prob[X_1(t) = n, X_2(t)=m] &= \prob[X_1(t)=n, X(t)= n +m] \\
					&= \prob[X_1(t)=n | X(t)=n+m]\prob[X(t)=n+m]\\
					&= {{n+m}\choose{n}}p^n(1-p)^m \frac{e^{-\lambda t}(\lambda t)^{m+n}}{(m+n)!}\\
					&= \frac{(n+m)!}{n!m!}p^n(1-p)^m e^{-\lambda p t}e^{-\lambda (1-p)t}\frac{(\lambda t)^m (\lambda t)^n}{(n+m)!}\\
					&= \frac{e^{-\lambda p t}(\lambda p t)^n}{n!}\frac{e^{-\lambda (1-p) t}(\lambda (1-p) t)^m}{m!}
				\end{split}
			\end{equation}
			I can factorize the two distributions and separate them, this shows the indipendence of the two Poisson distributions.
		\end{proof}
		For the result to be proved in general the proof should be done for every possible interval of time. It is sufficient to discriminate the following cases
		\begin{itemize}
			\item disjoint intervals: arrivals already independent $\rightarrow$ trivial
			\item $x_1$ inside $x_2$: I can apply the result I've just proved to $x_1$ first and then to the parts in $x_2$ that are not in $x_1$
			\item $x_1$ and $x_2$ overlapping just on one side: same as before, first apply the previous result to the overlapping part, then to the others
		\end{itemize}
	\end{itemize}
